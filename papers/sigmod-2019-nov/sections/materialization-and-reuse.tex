\section{Materialization and Reuse of Operations}\label{sec-materializaiton-and-reuse}
With the experiment graph constructed, we can look for optimization opportunities to both the feature engineering and the model building operations.
The experiment graph contains all the historical data operations.
By materialization the result of these operations we can reuse them for future workloads.

\subsection{Materialization of the Experiment Graph}
Since every historical operation may not be useful, we need to devise a mechanism for selecting the best data nodes to materialize.
Since we do not know the implementation details of the user-defined operations, we do not materialize nodes resulting from the user-defined feature engineering and aggregation operations.
In the rest of this chapter, the assumption is we have materialized every data node resulted from feature extraction, feature selection, common aggregation, and model training operations.
Materialization under limited resources is tackled by Bhattacherjee et al. \cite{bhattacherjee2015principles}.

\subsection{Reuse Optimization for Feature Engineering Operations}
Having our materialized experiment graph, we know devise a simple strategy to detect reuse opportunities when new machine learning workloads are executed.
Every edge can be uniquely identified in terms of the input columns and the operation.
Before executing a workload, we first use the same strategy for constructing the experiment graph, to transform the workload into the graph representation.
Using the graph representation, we can then search in the materialized graph for edges that have the same input columns (starting vertex) and operation type.
If the end-vertex of such edges are materialized, we can directly access them and skip executing the operation.

\subsubsection{Non-deterministic operations}
Some feature engineering operations are non-deterministic (such as count vectorizer).
Therefore, before the workload is executed we cannot know the resulting columns of such operations.
However, as described earlier, edges can be uniquely identified by the input vertex and the operation.
Therefore, for non-deterministic operations, we can look whether the same edge exists in the experiment graph and thus infer the output vertex.

\subsection{Reuse Optimization for Model Building Operations}
1. Aggregations are easy.
2. If input columns to the train is the same and hyperparameter are the same ==> trivial
3. If grid search hyperparameter search, for existing parameters reuse the trained model
4. If none existing, warmstarting
5. Random search, warm start with the best model
6. Advanced optimization, chapter 5

%\subsection{Materialization of Grid Search}
%\todo[inline]{Incomplete}
%In order to analyze whether or not we should materialize parts of the grid search, we first have to unpack it, and compare it with other grid search.
%Then, similar to Section \ref{sub-sec-materialization-of-transformed-data}, we materialize the parts that are executed frequently.
%
%%\subsection{Guided Grid-Search}
%%\todo[inline]{just an idea}
%%By extracting correlation between different parameters and the model quality we can provided a guided grid search, where we can provide some estimate or show the effects of a hyperparameter range on the model quality
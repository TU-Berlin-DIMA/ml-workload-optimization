\section{Conclusions} \label{sec-conclusion}
We present a system for optimizing machine learning workloads in collaborative environments.
We propose a graph representation of the artifacts of ML workloads, which we refer to as the Experiment Graph.
Using the Experiment Graph, we offer materialization and reuse algorithms.
We propose two materialization algorithms.
The first algorithm stores artifacts of the graph based on their likelihood of reappearing in future workloads.
The second algorithm is storage-aware, i.e., it takes deduplication information of the artifacts into account.
Given the set of materialized artifacts, for a new workload, our reuse algorithm finds the optimal execution plan in linear time.

We show that our collaborative optimizer improves the execution time of ML workloads by more than one order of magnitude for repeated executions and by 50\% for modified workloads.
In a real collaborative environment, where users re-execute and modify thousands of workloads, this amounts to hundreds to thousands of hours of execution time saved.
There is considerable overlap in intermediate datasets of ML workload.
As a result, our storage-aware materialization algorithm stores up to 8 times more artifacts than the simple materialization algorithm.
Lastly, our reuse algorithm finds the optimal execution plan and outperforms two baselines, i.e., loading all materialized vertices and recomputing all the vertices.

\textbf{Future work.}
Many data transformation in ML workloads are commutative, i.e., changing the order does not have an impact on the final result.
Currently, we reuse artifacts from EG only when they have the same preceding operations (in the same order) and ignore the commutative property of the operations.
IIn future work, we plan to exploit such transformations and define the concept of DAG equality in the presence of commutative operations.
Furthermore, EG contains valuable information about the meta-data and hyperparameters of the data preprocessing, feature engineering, and model training operations.
In future work, we plan to utilize this information to perform automatic ML pipeline construction and hyperparameter tuning \cite{Feurer15, thornton2013auto}.
Thus, fully or partially automating the process of designing ML pipelines.



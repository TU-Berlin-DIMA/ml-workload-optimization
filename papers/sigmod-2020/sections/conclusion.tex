\section{Conclusions} \label{sec-conclusion}
We present a system for optimizing machine learning workloads in collaborative environments.
We propose a graph representation of the artifacts of ML workloads, which we refer to as the Experiment Graph.
Using EG, we offer materialization and reuse algorithms.
We propose two materialization algorithms.
The heuristics-based algorithm stores artifacts of the graph based on their likelihood of reappearing in future workloads.
The storage-aware algorithm takes deduplication information of the artifacts into account when materializing them.
Given the set of materialized artifacts, for a new workload, our reuse algorithm finds the optimal execution plan in linear time.

We show that our collaborative optimizer improves the execution time of ML workloads by more than one order of magnitude for repeated executions and by 50\% for modified workloads.
In a real collaborative environment, where users re-execute and modify thousands of workloads, this amounts to hundreds to thousands of hours of execution time.
We also show that our storage-aware materialization can store up to 8 times more artifacts than the simple materialization algorithm.
Lastly, our reuse algorithm finds the optimal execution plan and outperforms two baselines, i.e., loading all materialized vertices and recomputing all the vertices.

\textbf{Future work.}
Many data transformation in ML workloads are commutative, i.e., changing the order does not have an impact on the final result.
Currently, we reuse artifacts from EG only when they have the same order of preceding operations and ignore the commutative property.
In future work, we plan to exploit such transformations and define the concept of DAG equality in the presence of commutative operations.
Furthermore, EG contains valuable information about the meta-data and hyperparameters of the data preprocessing, feature engineering, and model training operations.
In future work, we plan to utilize this information to perform automatic ML pipeline construction and hyperparameter tuning \cite{Feurer15, thornton2013auto, shang2019democratizing}; thus, fully or partially automating the process of designing ML pipelines.
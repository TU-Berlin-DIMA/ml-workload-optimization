\begin{abstract}
Effective collaboration between data scientists results in high-quality and efficient machine learning (ML) workloads.
In a collaborative environment, such as Kaggle or Google Colabratory, users typically re-execute or modify published scripts to recreate or improve the result.
This introduces many redundant data processing and model training operations.
Reusing the data generated by the redundant operations can lead to the more efficient execution of future workloads.
However, existing collaborative environments lack a data management component for storing and reusing the result of redundant operations.

In this paper, we present a system for the management of the data and computation in collaborative environments which aims to optimize the execution of ML workloads.
We utilize a graph to store the artifacts, i.e., raw and intermediate data or ML models, as vertices and operations of ML workloads as edges.
Storing all the artifacts, especially under limited storage budget, is not feasible as storage and retrieval cost may outweigh the recomputation cost.
To address this issue, we propose two algorithms for materializing artifacts with a high likelihood of future reuse.
%The algorithms utilize several statistics, such as access frequency, artifact size, and quality of the ML models.
Given the materialized artifacts inside the Experiment Graph, we devise a linear time reuse algorithm to find the optimal execution plan for incoming ML workloads.
Our reuse algorithm incurs a low overhead which is a requirement in collaborative environments where the rate of the incoming ML workloads may be high.
\hl{One sentence about the experiment results.}
\end{abstract}
\section{Evaluation} \label{sec-evaluation} 
In this section, we evaluate the performance of our collaborative optimizer system.
We focus on investigating the effect of our optimizations on the execution cost of workloads in collaborative environments.
We first describe the setup, including the hardware and the workloads we execute.
Then, we show the run-time improvement of our optimizer.
Then, we investigate the effect of the individual contributions, i.e., materialization and reuse algorithms, on the execution and storage cost.
\begin{table*}[t]
\begin{tabular}{lp{0.84\textwidth}rr}
\hline
\textbf{$ID$} & \textbf{$Description$}& \textbf{$N$}& \textbf{$S$}   \\
\hline
1 &  \parbox[t]{0.84\textwidth}{\linespread{0.5}\selectfont \small Real script titled 'start-here-a-gentle-introduction'. It includes several feature engineering operations before training logistic regression, random forest, and gradient boosted tree models.} & 397 & 14.5\\[0.4cm]

2 &   \parbox[t]{0.84\textwidth}{\linespread{0.5}\selectfont \small Real script titled 'introduction-to-manual-feature-engineering'. It joins multiple tables to generate a dataset and trains gradient boosted tree models.} & 406 & 25\\[0.4cm]

3 &   \parbox[t]{0.84\textwidth}{\linespread{0.5}\selectfont \small Real script titled 'introduction-to-manual-feature-engineering-p2'. It is similar to workload 2, but with larger datasets.} & 146 & 83.5\\[0.15cm]

4 & \parbox[t]{0.84\textwidth}{\linespread{0.5}\selectfont \small A modified version workload 1 submitted by the Kaggle user: 'crldata'. It modifies the hyperparameters of the gradient boosted tree.} & 280 & 10\\[0.4cm]

5 & \parbox[t]{0.84\textwidth}{\linespread{0.5}\selectfont \small A modified version workload 1 submitted by the Kaggle user: 'taozhongxiao'. It runs random and grid search for gradient boosted tree model on the dataset of workload 1.} & 402 & 13.8\\[0.4cm]

6 & \parbox[t]{0.84\textwidth}{\linespread{0.5}\selectfont \small Custom script based on workload 2. It trains a gradient boosted tree on the dataset of workload 2.} & 121 & 21\\[0.15cm]

7 & \parbox[t]{0.84\textwidth}{\linespread{0.5}\selectfont \small Custom script based on workload 3. It trains a gradient boosted tree on the dataset of workload 3.} & 145 & 83\\[0.15cm]

8 & \parbox[t]{0.84\textwidth}{\linespread{0.5}\selectfont \small Custom script that joins the features of workload 1 and 2. Then, it trains a gradient boosted tree on the joined dataset.} & 341 & 21.1\\
\hline
\end{tabular}
\caption{Kaggle workloads description. $N$ is number of the artifacts and $S$ is total size of the artifacts in GB.}
\label{kaggle-workload}
\end{table*}

\subsection{Setup}
\hl{We execute all the experiments on a server running Linux xxx with 128 GB of RAM and xxx GB of SSD.
We implement a prototype of our system in python 2.7 supporting both in-memory and disk-based Experiment Graph.
In the prototype, we implement the Experiment Graph using python's NetworkX library.
Unless specified otherwise, we run every experiment 5 times and report the average results (error bar included).}
We evaluate our proposed optimizations on two different sets of workloads.

\textbf{OpenML workloads.} In the OpenML workloads, we retrieve all the scikit-learn pipelines for task 31\footnote{https://www.openml.org/t/31}, i.e., classifying customers as good or bad credit risks using the German Credit data from the UCI repository \cite{asuncion2007uci}.
\todo[inline]{more details after i finish kaggle experiments}
%Table \ref{tab-openml-pipelines} shows the id, components, and number of executions of the OpenML pipelines.\footnote{information about each pipeline is available at https://www.openml.org/f/id}
%
%\begin{table}
%\setlength\tabcolsep{1.5pt} % This is to ensure the table does not go out of bound
%\begin{tabular}{llr}
%\hline
%\textbf{id} & \textbf{operations} & \textbf{\#exec}   \\
%\hline
% 5981&  \makecell[l]{Imputer$\rightarrow$ Standard scaler$\rightarrow$Logistic regression} &11        \\
% 7707&  \makecell[l]{Imputer$\rightarrow$Onehot encoder$\rightarrow$Standard scaler\\$\rightarrow $Variance thresholder$\rightarrow$SVM }&594 \\
% 8315&  \makecell[l]{Imputer$\rightarrow$Onehot encoder\\ $\rightarrow$Variance thresholder$\rightarrow $Random Forest} &1084  \\
%8353 & \makecell[l]{Imputer$\rightarrow$Onehot encoder\\$\rightarrow$Variance thresholder $\rightarrow $Svm}  & 1000\\
%8568 &  \makecell[l]{Imputer$\rightarrow$Onehot encoder\\$\rightarrow$Variance thresholder$\rightarrow $Random Forest} &555 \\
%\hline
%\end{tabular}
%\caption{OpenML pipeline descriptions.}
%\label{tab-openml-pipelines}
%\end{table}

\textbf{Kaggle workloads.} 
In the second set of workloads, we recreate the collaborative environment of the use case in Section \ref{sec-background}.
We introduced three workloads in the use case.
We retrieve two more workloads from the Kaggle competition, Home Credit Default Risk.
We also design 3 workloads based on the existing ones.
Table \ref{kaggle-workload} shows details of the workloads we utilize in our experiments.
The competition has 9 datasets with a total size of 2.5 GB\footnote{https://www.kaggle.com/c/home-credit-default-risk/data}.

\subsection{Execution Time}
\textbf{Kaggle Workloads.}
We start by showing the impact of our collaborative optimizer on the use case of Section \ref{sec-background}.
In the use case, we describe three workloads (Workloads 1-3 of Table \ref{kaggle-workload}).
Kaggle reports different users have copied and modified these workloads a total of 7000 times.
Therefore, at the very least, users execute these workloads 7000 times.
Figures \ref{exp-reuse-kaggle-same-workload} (a)-(c) show the result of repeating the execution of each workload.
The Experiment Graph is empty before the first run; therefore, both the baseline and our collaborative optimizer have the same run-time.
By materializing and reusing the artifacts, our collaborative optimizer reduces the run-time of the consecutive executions by one order of magnitude.
Workload 1 executes an external visualization command that plots a bivariate kernel density estimate, which incurs a large overhead.
Since our collaborative optimizer does not store the visualization information, it must re-execute the visualization command; thus, resulting in a smaller run-time reduction.
\begin{figure}
\begin{subfigure}[b]{0.33\linewidth}
\centering
%\includegraphics[width=\linewidth]{../images/experiment-results/kaggle_home_credit/execution_time/repetition/start_here_a_gentle_introduction}
 \resizebox{\columnwidth}{!}{%
\input{../images/experiment-results/kaggle_home_credit/execution_time/repetition/start_here_a_gentle_introduction.pgf}%
}

\caption{Workload 1}
\end{subfigure}%
\begin{subfigure}[b]{0.33\linewidth}
\centering
%\includegraphics[width=\linewidth]{../images/experiment-results/kaggle_home_credit/execution_time/repetition/introduction_to_manual_feature_engineering}
 \resizebox{\columnwidth}{!}{%
\input{../images/experiment-results/kaggle_home_credit/execution_time/repetition/introduction_to_manual_feature_engineering.pgf}%
}

\caption{Workload 2}
\end{subfigure}%
\begin{subfigure}[b]{0.33\linewidth}
\centering
%\includegraphics[width=\linewidth]{../images/experiment-results/kaggle_home_credit/execution_time/repetition/introduction_to_manual_feature_engineering_p2}
 \resizebox{\columnwidth}{!}{%
\input{../images/experiment-results/kaggle_home_credit/execution_time/repetition/introduction_to_manual_feature_engineering_p2.pgf}%
}
\caption{Workload 3}
\end{subfigure}
\begin{subfigure}[b]{\linewidth}
\centering
%\includegraphics[width=\linewidth]{../images/experiment-results/kaggle_home_credit/execution_time/different_workloads}
 \resizebox{\columnwidth}{!}{%
\input{../images/experiment-results/kaggle_home_credit/execution_time/different_workloads.pgf}%
}
\caption{Execution of several workloads one by one}
\end{subfigure}
\caption{Execution of Kaggle workloads (materialization budget = 32 GB). KG = Kaggle's infrastructure (our baseline), CO = Collaborative Optimizer.}
\label{exp-reuse-kaggle-same-workload}
\end{figure}

Figure \ref{exp-reuse-kaggle-same-workload} (d) shows the cumulative run-time of executing the 8 workloads of Table \ref{kaggle-workload} one after another.
This corresponds to a real scenario, where after some scripts of a collaborative environment gain popularity, i.e., Workloads 1-3, other users modify and try to improve them, i.e., Workloads 4-8.
The figure shows that even running every workload once decreases the cumulative run-time reduction by half.
In a real collaborative environment, there are hundreds of more modified scripts and possibly thousands of repeated execution of these scripts, resulting in 1000s of hours of reduction in the cumulative run-time.

\subsection{Materialization}
In this experiment, we run the workloads of Table \ref{kaggle-workload} under different materialization budgets.
Figure \ref{exp-sa-vs-simple-size} shows the total run-time of all the workloads under different materialization budgets for the storage-aware and simple materialization algorithms.
\todo[inline]{There seems to be a bug reporting the result.}
\begin{figure}
\begin{subfigure}[b]{\linewidth}
\centering
%\includegraphics[width=\linewidth]{../images/experiment-results/kaggle_home_credit/execution_time/repetition/start_here_a_gentle_introduction}
 \resizebox{0.5\columnwidth}{!}{%
\input{../images/experiment-results/kaggle_home_credit/materialization/run-time.pgf}%
}
\caption{Total run time of all the workloads with different budgets}
\label{exp-runtime-vs-mat-budget}
\end{subfigure}
\begin{subfigure}[b]{0.5\linewidth}
\centering
 \resizebox{\columnwidth}{!}{%
\input{../images/experiment-results/kaggle_home_credit/materialization/size-8.pgf}%
}
\caption{Budget = 8 GB}
\end{subfigure}%
\begin{subfigure}[b]{0.5\linewidth}
\centering
 \resizebox{\columnwidth}{!}{%
\input{../images/experiment-results/kaggle_home_credit/materialization/size-16.pgf}%
}

\caption{Budget = 16 GB}
\end{subfigure}
\begin{subfigure}[b]{0.5\linewidth}
\centering
 \resizebox{\columnwidth}{!}{%
\input{../images/experiment-results/kaggle_home_credit/materialization/size-32.pgf}%
}

\caption{Budget = 32 GB}
\end{subfigure}%
\begin{subfigure}[b]{0.5\linewidth}
\centering
 \resizebox{\columnwidth}{!}{%
\input{../images/experiment-results/kaggle_home_credit/materialization/size-64.pgf}%
}
\caption{Budget = 64 GB}
\end{subfigure}
\caption{Real size of the stored artifact for storage aware and simple materialization under different budgets (SA = storage-aware materialization, SM = simple materialization)  \todo[inline]{add total size and a straight line for budget}}
\label{exp-sa-vs-simple-size}
\end{figure}
Figure \ref{exp-sa-vs-simple-size} shows the real size of the stored artifacts under different budgets.
For the simple materialization algorithm, the maximum real size of the stored artifact never surpasses the budget.
However, in the storage-aware algorithm, we observe that the real size of the stored artifacts is 2 to 3 times more than the specified budget.
This shows that the rate of the duplicated columns in the artifacts of ML workloads is generally high.
Therefore, our storage-aware materialization algorithm can materialize more artifacts by de-duplicating the columns before storing them.

\textbf{Model Materialization. }
The goal of our materialization algorithm is to materialize high-quality models as soon as they appear in a new workload.
In this experiment, we run a typical scenario, where users always compare the score of their models with the score of the best performing model in the collaborative environment.
The OpenML platform assigns a time-stamp to every executed workload.
In this experiment, we execute all the OpenML workloads one by one and keep track of the best performing workload.
In every workload, as a post-processing step, we compare the score of the model with the score of the best performing model so far.
Figure \ref{exp-model-materialization} shows the result.
\todo[inline]{plot another figure, showing after how many repeated execution of the best pipeline did our system materializes it. It should be after 1 Unless the best pipeline has a very high run time.}

\begin{figure}
\begin{subfigure}[b]{0.5\linewidth}
\centering
 \resizebox{\columnwidth}{!}{%
\input{../images/experiment-results/openml/model_materialization/cumulative-runtime.pgf}%
}
\caption{Combined run-time}
\end{subfigure}%
\begin{subfigure}[b]{0.5\linewidth}
\centering
 \resizebox{\columnwidth}{!}{%
\input{../images/experiment-results/openml/model_materialization/bestpipeline-overhead.pgf}%
}
\caption{Best pipeline run-time}
\end{subfigure}
\caption{Effect of model materialization for OpenML workloads (CO = Collaborative Optimizer, OML = OpenML Default)}
\label{exp-model-materialization}
\end{figure}

\subsection{Reuse}
In this section, we compare our reuse algorithm we 2 baselines.
\begin{figure}
\begin{subfigure}[b]{0.5\linewidth}
\centering
 \resizebox{\columnwidth}{!}{%
\input{../images/experiment-results/kaggle_home_credit/reuse/simple-mat.pgf}%
}
\caption{Simple}
\end{subfigure}%
\begin{subfigure}[b]{0.5\linewidth}
\centering
 \resizebox{\columnwidth}{!}{%
\input{../images/experiment-results/kaggle_home_credit/reuse/storage-aware-mat.pgf}%
}

\caption{Storage-aware}
\end{subfigure}
\caption{Comparison of our linear reuse algorithm with two baselines under different materialization schemes (LN = linear, ALL\_C = all compute, ALL\_M = all materialized).}
\end{figure}

\subsection{Discussion}

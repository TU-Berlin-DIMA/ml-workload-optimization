\section{Reuse and Warmstarting Optimizations}\label{sec-reuse-and-warmstarting}
With the Experiment Graph constructed and materialized, our collaborative optimizer looks for opportunities to reuse existing materialized artifacts in the Experiment Graph and warmstart model training operations.
Every artifact of the incoming workload DAG has one of the three following states: (1) the artifact does not exist in the Experiment Graph, (2) the artifact exists in the Experiment Graph but is unmaterialized, and (3) the artifact is materialized.
For the first two states, the client must execute the operations of the DAG to generate the artifact.
However, when the artifact is materialized, we can either load it from the Experiment Graph or let the client execute the operations to compute the artifact.
Loading and computing an artifact incur costs.
In this section, we first describe our reuse algorithm, which selects a subset of the materialized objects, that outputs a DAG with the lowest execution time, i.e., cost of loading and cost of computing all the artifacts of the workload DAG.
Then, we discuss our warmstarting approach for model training operations.
Due to the stochastic behavior of some model training operations, we cannot always directly reuse a materialized model artifact.
Therefore, we warmstart the training operation of the model artifact, which leads to a decrease in training time.

\subsection{Reuse Algorithm} 
\textbf{Preliminaries and Notations.} 
We refer to the workload DAG as $WG$ and the Experiment Graph as $EG$.
For every vertex, $v \in WG$, we define $cost_l(v)$ as the cost (in seconds) of loading $v$ from $EG$ and $cost_c(v)$ as the computation cost (also in seconds) of $v$ given its parent vertices in $WG$.
If an artifact exist in $EG$ but is not materialized, then we set $cost_l(v)=\inf$.
For artifacts that do not exist in $EG$, $cost_l(v)$ and $cost_c(v)$ are undefined.
Such artifacts have never appeared in any previous workloads; thus, EG has no prior information about them.
Lastly, if an artifact is already computed inside $WG$, such as the source artifacts or pre-computed artifacts in interactive workloads, we assign $cost_c(v)=0$, this is because the artifact is already available in the client's memory.

\textbf{Linear-time Algorithm.}
Our reuse algorithm comprises two parts: forward-pass and backward-pass.
In forward-pass, the algorithm selects the set of materialized vertices to load from Experiment Graph into the workload DAG.
The backward-pass prunes any unnecessary materialized vertices before sending the optimized DAG to the client.

Algorithm \ref{forward-pass} shows the details of forward-pass.
For every vertex of $WG$, we compute its recreation cost, i.e., the cost of computing the vertex from the sources, and store it in the $recreation\_cost$ dictionary.
In collaborative environments, the client always loads the source artifacts completely.
Therefore, we set their recreation cost to 0 (Lines 1 and 2).
Then, we visit every vertex in their topological order.
If the client program has already computed a vertex inside $WG$, then we set its recreation cost to 0 (Lines 5 and 6).
Otherwise, we compute the execution cost of a vertex as the sum of the compute cost of the vertex and the recreation cost of its parents (Lines 8 and 9).
We then compare the load cost of the vertex with the execution cost and assign its recreation cost to the smaller of the two (Lines 10-14).
When the load cost is smaller, the algorithm adds the vertex to the set of materialized vertices.
Note that vertices that are not materialized have a load cost of infinity; therefore, the algorithm will never load an unmaterialized vertex.

\begin{algorithm}[h]
\KwData {$WG$: workload DAG, $EG$: Experiment Graph}
\KwResult {$\mathcal{M}$: Set of materialized vertices}
\For {$s \in sources(WG)$}{
	$recreation\_cost[s] \coloneqq 0$\;
}
$\mathcal{M} \coloneqq \emptyset$\;
\For {$v \leftarrow topological\_order(WG)$}{
	\eIf{$v$ computed in $WG$}{
		$recreation\_cost[v] \coloneqq 0$\; 		
		}{
		$p\_costs \coloneqq \sum\limits_{p \in parents(v)} recreation\_cost[p] $\;
		$execution\_cost \coloneqq cost_c(v) + p\_costs$\;
		\eIf {$ cost_l(v) < execution\_cost$}{
			$recreation\_cost[v] \coloneqq cost_l(v)$\;
			$\mathcal{M} \coloneqq \mathcal{M} \cup v$\;
		}{
			$recreation\_cost[v] \coloneqq recreation\_cost$\;
		}
	}
}
return $\mathcal{M}$\;
\caption{Forward-pass}\label{forward-pass}
\end{algorithm}
After forward-pass, we must prune the set of materialized artifacts to remove any artifact that is not part of the execution path.
Algorithm \ref{backward-pass} shows the details of the backward-pass algorithm.
In backward-pass, we visit every vertex of $WG$ starting from the terminal vertices.
For every vertex, if it belongs to the materialized vertex set, we add it to the final solution set and stop traversing its parents (Lines 4 and 5).
Otherwise, we continue traversing the parents of the vertex (Line 7).

\begin{algorithm}[h]
\KwData {$\mathcal{M}$: Materialized vertices, $WG$: workload DAG}
\KwResult {$\mathcal{M}_p$: Pruned set of materialized vertices}
$\mathcal{M}_p \coloneqq \emptyset$\;
$v\_queue \coloneqq terminals(WG)$\;
\While{$v \leftarrow v\_queue.next()$}{
	\eIf{$v \in \mathcal{M}$}{
			$\mathcal{M}_p \coloneqq \mathcal{M}_p \cup v$\;
	}{
		$v\_queue.add(parents(v))$\;
	}
}
return $\mathcal{M}_p$\;
\caption{Backward-pass}\label{backward-pass}
\end{algorithm}

Figure \ref{fig-reuse-algorithm} shows how our reuse algorithm (forward-pass and backward-pass) operates on an example workload DAG.
There are 3 source vertices in the workload DAG.
The algorithm starts with forward-pass, traversing the graph from the sources (Scenario \textcircled{\raisebox{-0.9pt}{\textbf{1}}}).
For materialized vertices with a larger load cost than execution cost (i.e., the sum of the compute cost and parent's recreation costs), the algorithm sets the recreation cost to the execution cost (Scenario \textcircled{\raisebox{-0.9pt}{\textbf{2}}}).
For vertices that exist in EG but are unmaterialized, the algorithm chooses to compute them (Scenario \textcircled{\raisebox{-0.9pt}{\textbf{3}}}).
If a vertex is already computed inside the workload DAG, then the algorithm sets its recreation cost to zero (Scenario \textcircled{\raisebox{-0.9pt}{\textbf{4}}}).
For materialized vertices, which have a smaller load cost than the execution cost, the algorithm sets the recreation cost to the load cost of the vertex (Scenario \textcircled{\raisebox{-0.9pt}{\textbf{5}}}).
For example, for the materialized vertex with label $v_2$, the total execution cost is $2 + 5 + 10 = 17$, which is larger than its load cost of $16$.
Once the traversal reaches a node that does not exist in EG, the forward-pass stops (Scenario \textcircled{\raisebox{-0.9pt}{\textbf{6}}}).
At this stage, forward-pass has selected the materialized vertices $v_2$ and $v_3$ for reuse..
Then the algorithm starts backward-pass from the terminal vertex (Scenario \textcircled{\raisebox{-0.9pt}{\textbf{7}}}).
Once the backward-pass visits a materialized vertex, it stops traversing its parents.
The backward-pass removes any materialized vertex that it does not visit from the final solution (Scenario \textcircled{\raisebox{-0.9pt}{\textbf{8}}}).
For example, since $v_3$ is materialized, backward-pass stops visiting its parents; thus, removing $v_2$ from the final solution.

\begin{figure}
\centering
\includegraphics[width=\linewidth]{../images/tikz-standalone/reuse-algorithm}
\caption{Reuse Algorithm Example. Each vertex has the label $\langle C,L \rangle$, where $C$ is the compute cost and $L$ is the load cost. $T$ represent the recreation cost passed along to the children vertices. Numbered circles show different scenarios.}
\label{fig-reuse-algorithm}
\end{figure}

\textbf{Complexity.} 
Both forward-pass and backward-pass traverse the workload DAG once, resulting in $2*|V|$ vertex visits, where $V$ is the set of vertices in the workload DAG.
Therefore, our reuse algorithm has a worst-case complexity of $\mathcal{O}(|V|)$.
However, the number of vertex visits in each pass is smaller than $|V|$ because of the early-stopping conditions in forward and backward passes.
Forward-pass stops traversing a path when a vertex is not in EG and backward-pass stops traversing the parents of a vertex when the vertex is in the materialized set.
Thus, the reuse algorithm generates the optimal execution plan with a small overhead.
This is an important requirement of the collaborative environments.
In a typical collaborative environment, many clients send workloads to the server for optimization.
Furthermore, in interactive workloads, clients expect a response very fast.
Therefore, If the reuse algorithm incurs a large overhead, the server does not respond in time or becomes unresponsive.

\subsection{Warmstarting}
Many model training operations include random processes, where a random seed parameter controls the random behavior.
For example, in random forests, to decide when to split a tree node, features are randomly permuted.
Thus, two training operations on the same dataset with the same hyperparameters may result in different models if the random seeds are different.
In such scenarios, we cannot reuse a materialized model in EG instead of a model artifact in the workload DAG.
Therefore, instead of reusing a model, we try to warmstart the model training operations using the models in EG.
In warmstarting, instead of randomly initializing the parameters of a model before training, we initialize the model parameters to a previously trained model.
Warmstarting has shown to decrease the total training time \cite{baylor2017tfx}.

Once we encounter a model in the workload DAG during the forward-pass of the reuse algorithm, we check if there are candidates for warmstarting in EG.
A warmstarting candidate is a model that is trained on the same artifact as the model in the workload DAG.
When there is more than one candidate for warmstarting, we select the model with the highest evaluation score.
Finally, we initialize the model training operation with the selected model.
\section{Background and Use Case} \label{sec-background}
In this section, we first present a typical collaborative environment.
Then, we discuss a motivating example.

\textbf{Collaborative Environment for Data Science.}
A typical collaborative environment consists of a client and server.
Users write a script to fetch datasets from the server, analyze the data, and train ML models.
Then, the client executes the script.
Although the client can be a single machine, users typically utilize Jupyter notebooks \cite{Kluyver:2016aa} to write and execute their scripts in isolated containers \cite{merkel2014docker} within the server itself \cite{kagglewebsite, googlecolab, netflix-notebook}.
Users can publish the results and the scripts on the server.
Isolated execution environments enable better resource allocation for running scripts.

\textbf{Motivating Example.}
Kaggle is a collaborative environment that enables users and organizations to publish datasets and organize ML competitions.
In every competition, the organizer defines a task.
Users submit their solutions as ML scripts.
Kaggle utilizes docker containers, called kernels, to execute user workloads.
% If the workload produces ML model artifacts, the users can choose to submit them and measure their performance on test datasets.

For example, let's consider the competition \textit{Home Credit Default Risk}\footnote{https://www.kaggle.com/c/home-credit-default-risk/}.
The task is to train a classification model to predict whether clients can repay their loans.
There are a total of 9 datasets, 8 for training and 1 for evaluation, with a total size of 2.5 GB.
The goal of the submitted workloads is to train an ML model that maximizes the area under the ROC curve, which measures how well a classifier works.
Three of the most popular submitted workloads are copied and edited by different users more than 7000 times \cite{start-here-a-gentle-intro, introduction-to-manual-feature-engineering, introduction-to-manual-feature-engineering-p2}.
The three workloads produce 100s of data artifacts and several ML models with a total size of 125 GB.
The execution time of each workload is between 200 to 400 seconds.
% Kaggle does not provide any information on the number of workload executions.
% However, the number of users who copied these workloads indicates the potentially large number of executions, i.e., at least 7000 times.

Kaggle does not store the artifacts, nor does it offer automatic reuse.
Therefore, every time a user executes these workloads (or a modified version of them), Kaggle runs them from scratch.
Our system, which stores the artifacts and reuses them later, can save hundreds of hours of execution time only for the three workloads in the motivating example.
% , which benefits such a collaborative environment by reducing the amount of required resource and operation cost.
In the next sections, we show how we selectively store artifacts, given a storage budget, and how we quickly find the relevant artifacts for reuse.
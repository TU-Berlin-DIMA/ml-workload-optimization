{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import sys\n",
    "import os\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import cPickle as pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "ROOT = '/Users/bede01/Documents/work/phd-papers/ml-workload-optimization/'\n",
    "ROOT_PACKAGE_DIRECTORY = '/Users/bede01/Documents/work/phd-papers/ml-workload-optimization/code/collaborative-optimizer'\n",
    "root_data = ROOT + '/data'\n",
    "\n",
    "sys.path.append(ROOT_PACKAGE_DIRECTORY)\n",
    "from experiment_graph.execution_environment import ExecutionEnvironment\n",
    "from experiment_graph.executor import CollaborativeExecutor\n",
    "from experiment_graph.workload import Workload\n",
    "\n",
    "\n",
    "DATABASE_PATH = root_data + '/experiment_graphs/home-credit-default-risk/materialized-no-groupby'\n",
    "N_ESTIMATOR = 100\n",
    "from experiment_graph.optimizations.Reuse import HelixReuse\n",
    "from experiment_graph.optimizations.Reuse import LinearTimeReuse\n",
    "reuse_type=HelixReuse.NAME\n",
    "\n",
    "def plot_graph(graph, figsize=(20,10),prog='dot', vertex_labels=True, edge_labels = True):\n",
    "    from networkx.drawing.nx_agraph import graphviz_layout\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    ax = f.add_subplot(1, 1, 1)\n",
    "    pos = graphviz_layout(graph, prog=prog, args='')\n",
    "    #pos = nx.drawing.layout.spring_layout(graph)\n",
    "    jet = plt.get_cmap('gist_rainbow')\n",
    "    nx.draw_networkx(\n",
    "        graph,\n",
    "        cmap=jet,\n",
    "        # vmin=0,\n",
    "        # vmax=len(unique_types),\n",
    "        node_shape='s',\n",
    "        pos=pos,\n",
    "        with_labels=False,\n",
    "        ax=ax)\n",
    "    if vertex_labels:\n",
    "        labels = {n_id:'{},{}'.format(n_id[:10],node.values()) for n_id, node in graph.nodes(data=True)}\n",
    "        nx.draw_networkx_labels(graph,pos=pos,labels=labels)\n",
    "    if edge_labels:\n",
    "        nx.draw_networkx_edge_labels(\n",
    "            graph,\n",
    "            pos=pos,\n",
    "            edge_labels={(u, v): d for u, v, d in graph.edges(data=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kaggle_home_credit', '.DS_Store', 'optimized_app_train.csv', 'baseline_app_train.csv', 'profiles', 'openml', 'experiment_graphs']\n",
      "creating a new root node\n",
      "executing 1 steps to compute vertex 4A3F3862EC3739B17293F6C0469C4825\n",
      "('Training data shape: ', (246008, 122))\n",
      "executing 1 steps to compute vertex 51706642912947F8FE42884FC3D178EC\n",
      "creating a new root node\n",
      "executing 1 steps to compute vertex 86CFD76958926538A85C44814257E4D9\n",
      "('Testing data shape: ', (61503, 121))\n",
      "executing 1 steps to compute vertex AF81475B28FC81FF5FDA3450B04F83B8\n",
      "creating a new root node\n",
      "executing 2 steps to compute vertex 5F1A78DEF5005C37A39167096883035E\n",
      "finished execution in 8.332056 seconds\n",
      "running again\n",
      "['kaggle_home_credit', '.DS_Store', 'optimized_app_train.csv', 'baseline_app_train.csv', 'profiles', 'openml', 'experiment_graphs']\n",
      "['4A3F3862EC3739B17293F6C0469C4825', 'application_train.csv{}']\n",
      "remote node [4A3F3862EC3739B17293F6C0469C4825]:{'mat': True, 'recreation_cost': 0.05, 'meta_freq': 1, 'n_potential': 0, 'load_cost': 0.012, 'n_recreation_cost': 0.1958090217504316, 'profile_load_cost': 0.010499999999999999, 'potential': 0, 'type': 'Agg', 'root': False, 'data': <experiment_graph.graph.node.Agg object at 0x1161aedd0>, 'compute_cost': 0.05, 'size': 0.1171875}\n",
      "load cost 4A3F3862EC3739B17293F6C0469C4825 = 0.012\n",
      "materialized_vertices: set(['4A3F3862EC3739B17293F6C0469C4825'])\n",
      "4A3F3862EC3739B17293F6C0469C4825 was copied directly from experiment graph\n",
      "('Training data shape: ', (246008, 122))\n",
      "['51706642912947F8FE42884FC3D178EC', 'application_train.csv{}']\n",
      "remote node [51706642912947F8FE42884FC3D178EC]:{'mat': True, 'recreation_cost': 1.679, 'meta_freq': 1, 'n_potential': 0, 'load_cost': 0.333, 'n_recreation_cost': 0.09660039594093281, 'profile_load_cost': 0.004019712039910109, 'potential': 0, 'type': 'Dataset', 'root': False, 'data': <experiment_graph.graph.node.Dataset object at 0x1161aee90>, 'compute_cost': 1.679, 'size': 7.9765625}\n",
      "load cost 51706642912947F8FE42884FC3D178EC = 0.333\n",
      "materialized_vertices: set(['51706642912947F8FE42884FC3D178EC'])\n",
      "51706642912947F8FE42884FC3D178EC was copied directly from experiment graph\n",
      "['application_test.csv{}', '86CFD76958926538A85C44814257E4D9']\n",
      "remote node [86CFD76958926538A85C44814257E4D9]:{'mat': True, 'recreation_cost': 0.012, 'meta_freq': 1, 'n_potential': 0, 'load_cost': 0.016, 'n_recreation_cost': 0.046994165220103586, 'profile_load_cost': 0.010499999999999999, 'potential': 0, 'type': 'Agg', 'root': False, 'data': <experiment_graph.graph.node.Agg object at 0x1161aebd0>, 'compute_cost': 0.012, 'size': 0.1171875}\n",
      "load cost 86CFD76958926538A85C44814257E4D9 = 0.016\n",
      "materialized_vertices: set([])\n",
      "executing 1 steps to compute vertex 86CFD76958926538A85C44814257E4D9\n",
      "('Testing data shape: ', (61503, 121))\n",
      "['application_test.csv{}', 'AF81475B28FC81FF5FDA3450B04F83B8']\n",
      "remote node [AF81475B28FC81FF5FDA3450B04F83B8]:{'mat': True, 'recreation_cost': 2.602, 'meta_freq': 1, 'n_potential': 0, 'load_cost': 0.267, 'n_recreation_cost': 0.14677567867327992, 'profile_load_cost': 0.004099929114163947, 'potential': 0, 'type': 'Dataset', 'root': False, 'data': <experiment_graph.graph.node.Dataset object at 0x1161aee50>, 'compute_cost': 2.602, 'size': 8.1357421875}\n",
      "load cost AF81475B28FC81FF5FDA3450B04F83B8 = 0.267\n",
      "materialized_vertices: set(['AF81475B28FC81FF5FDA3450B04F83B8'])\n",
      "AF81475B28FC81FF5FDA3450B04F83B8 was copied directly from experiment graph\n",
      "['885517FA12002C9EFFCF2618E23CEB6C', '5F1A78DEF5005C37A39167096883035E', 'application_train.csv{}']\n",
      "remote node [885517FA12002C9EFFCF2618E23CEB6C]:{'mat': False, 'recreation_cost': 0.094, 'meta_freq': 1, 'n_potential': 0, 'load_cost': 0.013, 'n_recreation_cost': 2.244567011382626e-05, 'profile_load_cost': 0.0494, 'potential': 0, 'type': 'Feature', 'root': False, 'data': <experiment_graph.graph.node.Feature object at 0x1161a32d0>, 'compute_cost': 0.094, 'size': 1921.9375}\n",
      "load cost 885517FA12002C9EFFCF2618E23CEB6C = 10000000\n",
      "remote node [5F1A78DEF5005C37A39167096883035E]:{'mat': True, 'recreation_cost': 4.487, 'meta_freq': 1, 'n_potential': 0, 'load_cost': 0.098, 'n_recreation_cost': 0.5137982927451383, 'profile_load_cost': 0.3590999999999999, 'potential': 0, 'type': 'Agg', 'root': False, 'data': <experiment_graph.graph.node.Agg object at 0x1161ae7d0>, 'compute_cost': 4.393, 'size': 4.0078125}\n",
      "load cost 5F1A78DEF5005C37A39167096883035E = 0.098\n",
      "materialized_vertices: set(['5F1A78DEF5005C37A39167096883035E'])\n",
      "5F1A78DEF5005C37A39167096883035E was copied directly from experiment graph\n",
      "['885517FA12002C9EFFCF2618E23CEB6C', 'application_train.csv{}']\n",
      "remote node [885517FA12002C9EFFCF2618E23CEB6C]:{'mat': False, 'recreation_cost': 0.094, 'meta_freq': 1, 'n_potential': 0, 'load_cost': 0.013, 'n_recreation_cost': 2.244567011382626e-05, 'profile_load_cost': 0.0494, 'potential': 0, 'type': 'Feature', 'root': False, 'data': <experiment_graph.graph.node.Feature object at 0x1161a32d0>, 'compute_cost': 0.094, 'size': 1921.9375}\n",
      "load cost 885517FA12002C9EFFCF2618E23CEB6C = 10000000\n",
      "materialized_vertices: set([])\n",
      "executing 1 steps to compute vertex 885517FA12002C9EFFCF2618E23CEB6C\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAD8CAYAAAChHgmuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAEtpJREFUeJzt3X2wXVd93vHvgwXBTvALkXA9lh1B\nq6RRnYaYG6NOmgbqYmRnYpGWUjOlVjweKxObtmkynTg0UznQziTTAq07xMEUjSVaXgwJoE7sqsIh\n8bRTYV8X6jdCrYLBEgYrliOHmOLY/PrHWYJj5ereLemue3zP/X5mzty9135ZvyXJfrT3XtonVYUk\nST29YNIFSJKmn2EjSerOsJEkdWfYSJK6M2wkSd0ZNpKk7gwbSVJ3ho0kqTvDRpLU3apJF/B8sXr1\n6lq3bt2ky5CkZeWee+7546pas9B+hk2zbt06ZmdnJ12GJC0rSb48ZD9vo0mSujNsJEndGTaSpO4M\nG0lSd4aNJKk7w0aS1J1hI0nqzrCRJHVn2EiSuvMNAovhhjMm2PfhyfUtSQN5ZSNJ6s6wkSR1Z9hI\nkrozbCRJ3Rk2kqTuDBtJUneGjSSpO8NGktSdYSNJ6s6wkSR1Z9hIkrozbCRJ3Rk2kqTuDBtJUneG\njSSpO8NGktSdYSNJ6s6wkSR1Z9hIkrrrFjZJzkvy6SQPJnkgyT9t7S9NsifJQ+3nWa09SW5Msi/J\nvUkuHDvXlrb/Q0m2jLW/Ksl97Zgbk2S+PiRJk9HzyuYZ4JeragOwEbguyQbgeuCOqloP3NHWAS4F\n1rfPVuAmGAUHsA14NXARsG0sPG4Crhk7blNrP1YfkqQJ6BY2VfVoVf2vtvynwOeBc4HNwI622w7g\nDW15M7CzRvYCZyY5B3g9sKeqDlXVE8AeYFPbdnpV7a2qAnYeda65+pAkTcCSPLNJsg74MeAzwNlV\n9Wjb9DXg7LZ8LvDI2GH7W9t87fvnaGeePiRJE9A9bJJ8H/A7wC9W1ZPj29oVSfXsf74+kmxNMptk\n9uDBgz3LkKQVrWvYJHkho6D5z1X1u6356+0WGO3nY639AHDe2OFrW9t87WvnaJ+vj+eoqpuraqaq\nZtasWXNig5QkLajnbLQA7wc+X1XvGtu0Czgyo2wL8Mmx9ivbrLSNwOF2K2w3cEmSs9rEgEuA3W3b\nk0k2tr6uPOpcc/UhSZqAVR3P/RPAPwLuS/K51vY24DeAW5NcDXwZeFPbdhtwGbAPeAq4CqCqDiV5\nB3B32+/tVXWoLV8L3AKcCtzePszThyRpArqFTVX9dyDH2HzxHPsXcN0xzrUd2D5H+yxwwRztj8/V\nhyRpMnyDgCSpO8NGktSdYSNJ6s6wkSR1Z9hIkrozbCRJ3Rk2kqTuDBtJUneGjSSpO8NGktSdYSNJ\n6s6wkSR1Z9hIkrozbCRJ3Rk2kqTuDBtJUneGjSSpO8NGktSdYSNJ6s6wkSR1Z9hIkrozbCRJ3Rk2\nkqTuDBtJUneGjSSpO8NGktSdYSNJ6s6wkSR1Z9hIkrozbCRJ3Rk2kqTuDBtJUneGjSSpO8NGktSd\nYSNJ6s6wkSR1Z9hIkrrrFjZJtid5LMn9Y203JDmQ5HPtc9nYtl9Nsi/JF5K8fqx9U2vbl+T6sfaX\nJ/lMa/9Ikhe19u9p6/va9nW9xihJGqbnlc0twKY52t9dVa9sn9sAkmwArgD+Wjvmt5KckuQU4D3A\npcAG4M1tX4DfbOf6K8ATwNWt/Wrgidb+7rafJGmCuoVNVd0JHBq4+2bgw1X1rar6ErAPuKh99lXV\nF6vqaeDDwOYkAf428LF2/A7gDWPn2tGWPwZc3PaXJE3IJJ7ZvDXJve0221mt7VzgkbF99re2Y7V/\nP/AnVfXMUe3POVfbfrjtL0makKUOm5uAvwy8EngUeOcS9/8cSbYmmU0ye/DgwUmWIklTbUnDpqq+\nXlXPVtW3gfcxuk0GcAA4b2zXta3tWO2PA2cmWXVU+3PO1baf0fafq56bq2qmqmbWrFlzssOTJB3D\nkoZNknPGVn8WODJTbRdwRZtJ9nJgPXAXcDewvs08exGjSQS7qqqATwNvbMdvAT45dq4tbfmNwO+3\n/SVJE7Jq4V1OTJIPAa8BVifZD2wDXpPklUABDwM/D1BVDyS5FXgQeAa4rqqebed5K7AbOAXYXlUP\ntC5+Bfhwkn8FfBZ4f2t/P/CBJPsYTVC4otcYJUnDZMhf+pP8SFXdtwT1TMzMzEzNzs6e2ME3nLG4\nxRxX34cn17ekFS/JPVU1s9B+Q2+j/VaSu5Jcm2SC/2eVJC1Hg8Kmqn4S+IeMHrzfk+SDSV7XtTJJ\n0tQYPEGgqh4Cfo3Rs5KfAm5M8kdJ/m6v4iRJ02FQ2CT560neDXye0b/c/5mq+uG2/O6O9UmSpsDQ\n2Wj/AfiPwNuq6ptHGqvqq0l+rUtlkqSpMTRsfhr45th05BcAL66qp6rqA92qkyRNhaHPbD4FnDq2\nflprkyRpQUPD5sVV9Y0jK235tD4lSZKmzdCw+bMkFx5ZSfIq4Jvz7C9J0ncMfWbzi8BHk3wVCPCX\ngH/QrSpJ0lQZFDZVdXeSvwr8UGv6QlX9eb+yJEnT5HhexPnjwLp2zIVJqKqdXaqSJE2VQWGT5AOM\nvvTsc8CzrbkAw0aStKChVzYzwAa/F0aSdCKGzka7n9GkAEmSjtvQK5vVwINJ7gK+daSxqi7vUpUk\naaoMDZsbehYhSZpuQ6c+/2GSHwDWV9WnkpzG6GuaJUla0NCvGLgG+Bjw3tZ0LvCJXkVJkqbL0AkC\n1wE/ATwJ3/kitZf1KkqSNF2Ghs23qurpIytJVjH6dzaSJC1oaNj8YZK3AacmeR3wUeC/9CtLkjRN\nhobN9cBB4D7g54HbAL+hU5I0yNDZaN8G3tc+kiQdl6HvRvsSczyjqapXLHpFkqSpczzvRjvixcDf\nB166+OVIkqbRoGc2VfX42OdAVf074Kc71yZJmhJDb6NdOLb6AkZXOsfzXTiSpBVsaGC8c2z5GeBh\n4E2LXo0kaSoNnY322t6FSJKm19DbaL803/aqetfilCNJmkbHMxvtx4Fdbf1ngLuAh3oUJUmaLkPD\nZi1wYVX9KUCSG4Dfq6q39CpMkjQ9hr6u5mzg6bH1p1ubJEkLGnplsxO4K8nH2/obgB19SpIkTZuh\ns9H+dZLbgZ9sTVdV1Wf7lSVJmiZDb6MBnAY8WVX/Htif5OWdapIkTZmhXwu9DfgV4Fdb0wuB/7TA\nMduTPJbk/rG2lybZk+Sh9vOs1p4kNybZl+Te8TcWJNnS9n8oyZax9lclua8dc2OSzNeHJGlyhl7Z\n/CxwOfBnAFX1VeAlCxxzC7DpqLbrgTuqaj1wR1sHuBRY3z5bgZtgFBzANuDVwEXAtrHwuAm4Zuy4\nTQv0IUmakKFh83RVFe1rBpJ870IHVNWdwKGjmjfz3YkFOxhNNDjSvrNG9gJnJjkHeD2wp6oOVdUT\nwB5gU9t2elXtbXXtPOpcc/UhSZqQoWFza5L3MgqBa4BPcWJfpHZ2VT3alr/Gd6dPnws8Mrbf/tY2\nX/v+Odrn6+MvSLI1yWyS2YMHD57AcCRJQwydjfZvk7wOeBL4IeBfVtWek+m4qirJX/hCtsW0UB9V\ndTNwM8DMzEzXWiRpJVswbJKcAnyqvYzzpAIG+HqSc6rq0XYr7LHWfgA4b2y/ta3tAPCao9r/oLWv\nnWP/+fqQJE3IgrfRqupZ4NtJzliE/nYBR2aUbQE+OdZ+ZZuVthE43G6F7QYuSXJWmxhwCbC7bXsy\nycY2C+3Ko841Vx+SpAkZ+gaBbwD3JdlDm5EGUFX/5FgHJPkQo6uS1Un2M5pV9huMnv9cDXyZ734n\nzm3AZcA+4Cngqnb+Q0neAdzd9nt7VR2ZdHAtoxlvpwK3tw/z9CFJmpChYfO77TNYVb35GJsunmPf\nAq47xnm2A9vnaJ8FLpij/fG5+pAkTc68YZPk/Kr6SlX5HjRJ0glb6JnNJ44sJPmdzrVIkqbUQmGT\nseVX9CxEkjS9FgqbOsayJEmDLTRB4EeTPMnoCufUtkxbr6o6vWt1kqSpMG/YVNUpS1WIJGl6Hc/3\n2UiSdEIMG0lSd4aNJKk7w0aS1J1hI0nqzrCRJHVn2EiSujNsJEndGTaSpO4MG0lSd4aNJKk7w0aS\n1J1hI0nqzrCRJHVn2EiSujNsJEndGTaSpO4MG0lSd4aNJKk7w0aS1J1hI0nqzrCRJHVn2EiSujNs\nJEndGTaSpO4MG0lSd4aNJKk7w0aS1J1hI0nqzrCRJHU3kbBJ8nCS+5J8Lslsa3tpkj1JHmo/z2rt\nSXJjkn1J7k1y4dh5trT9H0qyZaz9Ve38+9qxWfpRSpKOmOSVzWur6pVVNdPWrwfuqKr1wB1tHeBS\nYH37bAVuglE4AduAVwMXAduOBFTb55qx4zb1H44k6VieT7fRNgM72vIO4A1j7TtrZC9wZpJzgNcD\ne6rqUFU9AewBNrVtp1fV3qoqYOfYuSRJEzCpsCngvyW5J8nW1nZ2VT3alr8GnN2WzwUeGTt2f2ub\nr33/HO2SpAlZNaF+/2ZVHUjyMmBPkj8a31hVlaR6F9GCbivA+eef37s7SVqxJnJlU1UH2s/HgI8z\neuby9XYLjPbzsbb7AeC8scPXtrb52tfO0T5XHTdX1UxVzaxZs+ZkhyVJOoYlD5sk35vkJUeWgUuA\n+4FdwJEZZVuAT7blXcCVbVbaRuBwu922G7gkyVltYsAlwO627ckkG9sstCvHziVJmoBJ3EY7G/h4\nm428CvhgVf3XJHcDtya5Gvgy8Ka2/23AZcA+4CngKoCqOpTkHcDdbb+3V9WhtnwtcAtwKnB7+0iS\nJmTJw6aqvgj86BztjwMXz9FewHXHONd2YPsc7bPABSddrCRpUTyfpj5LkqaUYSNJ6s6wkSR1Z9hI\nkrozbCRJ3Rk2kqTuDBtJUneGjSSpO8NGktSdYSNJ6s6wkSR1Z9hIkrozbCRJ3Rk2kqTuDBtJUneG\njSSpO8NGktSdYSNJ6s6wkSR1Z9hIkrozbCRJ3Rk2kqTuDBtJUnerJl2AJAm44YwJ9n24exde2UiS\nujNsJEndGTaSpO4MG0lSd4aNJKk7w0aS1J1hI0nqzrCRJHVn2EiSujNsJEndGTaSpO4MG0lSd4aN\nJKm7qQ2bJJuSfCHJviTXT7oeSVrJpjJskpwCvAe4FNgAvDnJhslWJUkr11SGDXARsK+qvlhVTwMf\nBjZPuCZJWrGmNWzOBR4ZW9/f2iRJE7Civ6kzyVZga1v9RpIvnOCpVgN/vDhVHadfz0S6ZZJjnhzH\nvDKsvDH/ek5mzD8wZKdpDZsDwHlj62tb23NU1c3AzSfbWZLZqpo52fMsJ455ZXDMK8NSjHlab6Pd\nDaxP8vIkLwKuAHZNuCZJWrGm8sqmqp5J8lZgN3AKsL2qHphwWZK0Yk1l2ABU1W3AbUvU3UnfiluG\nHPPK4JhXhu5jTlX17kOStMJN6zMbSdLziGFzHBZ6BU6S70nykbb9M0nWLX2Vi2vAmH8pyYNJ7k1y\nR5JB0yCfz4a+6ijJ30tSSZb1zKUh403ypvb7/ECSDy51jYttwJ/r85N8Osln25/tyyZR52JKsj3J\nY0nuP8b2JLmx/Zrcm+TCRS2gqvwM+DCaaPB/gVcALwL+N7DhqH2uBX67LV8BfGTSdS/BmF8LnNaW\nf2EljLnt9xLgTmAvMDPpujv/Hq8HPguc1dZfNum6l2DMNwO/0JY3AA9Puu5FGPffAi4E7j/G9suA\n24EAG4HPLGb/XtkMN+QVOJuBHW35Y8DFSSb2ry4XwYJjrqpPV9VTbXUvo3/TtJwNfdXRO4DfBP7f\nUhbXwZDxXgO8p6qeAKiqx5a4xsU2ZMwFnN6WzwC+uoT1dVFVdwKH5tllM7CzRvYCZyY5Z7H6N2yG\nG/IKnO/sU1XPAIeB71+S6vo43tf+XM3ob0bL2YJjbrcXzquq31vKwjoZ8nv8g8APJvkfSfYm2bRk\n1fUxZMw3AG9Jsp/RrNZ/vDSlTVTX13xN7dRnLa0kbwFmgJ+adC09JXkB8C7g5yZcylJaxehW2msY\nXbnemeRHqupPJlpVX28Gbqmqdyb5G8AHklxQVd+edGHLlVc2ww15Bc539kmyitHl9+NLUl0fg177\nk+TvAP8CuLyqvrVEtfWy0JhfAlwA/EGShxnd2961jCcJDPk93g/sqqo/r6ovAf+HUfgsV0PGfDVw\nK0BV/U/gxYzemTbNBv33fqIMm+GGvAJnF7ClLb8R+P1qT96WqQXHnOTHgPcyCprlfi8fFhhzVR2u\nqtVVta6q1jF6TnV5Vc1OptyTNuTP9ScYXdWQZDWj22pfXMoiF9mQMX8FuBggyQ8zCpuDS1rl0tsF\nXNlmpW0EDlfVo4t1cm+jDVTHeAVOkrcDs1W1C3g/o8vtfYwexF0xuYpP3sAx/xvg+4CPtrkQX6mq\nyydW9EkaOOapMXC8u4FLkjwIPAv886patlfsA8f8y8D7kvwzRpMFfm6Z/8WRJB9i9JeG1e1Z1Dbg\nhQBV9duMnk1dBuwDngKuWtT+l/mvnyRpGfA2miSpO8NGktSdYSNJ6s6wkSR1Z9hIkrozbCRJ3Rk2\nkqTuDBtJUnf/H71X7zcasl/BAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bae8f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"Optimized workload 1\n",
    "\n",
    "This script is the optimized version of the workload 'start_here_a_gentle_introduction'\n",
    "which utilizes our Experiment Graph for optimizing the workload\n",
    "\"\"\"\n",
    "import os\n",
    "import warnings\n",
    "# matplotlib and seaborn for plotting\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "from experiment_graph.workload import Workload\n",
    "\n",
    "matplotlib.use('ps')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# numpy and pandas for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Experiment Graph\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class start_here_a_gentle_introduction(Workload):\n",
    "\n",
    "    def run(self, execution_environment, root_data, verbose=0):\n",
    "        print(os.listdir(root_data))\n",
    "        app_train = execution_environment.load(root_data + '/kaggle_home_credit/application_train.csv')\n",
    "        print('Training data shape: ', app_train.shape().data(verbose))\n",
    "        app_train.head().data(verbose)\n",
    "\n",
    "        app_test = execution_environment.load(root_data + '/kaggle_home_credit/application_test.csv')\n",
    "        print('Testing data shape: ', app_test.shape().data(verbose))\n",
    "        app_test.head().data(verbose)\n",
    "\n",
    "        test_labels = execution_environment.load(root_data + '/kaggle_home_credit/application_test_labels.csv')\n",
    "\n",
    "        app_train['TARGET'].value_counts().data(verbose)\n",
    "\n",
    "        app_train['TARGET'].data(verbose).astype(int).plot.hist()\n",
    "\n",
    "#         # Function to calculate missing values by column# Funct\n",
    "#         def missing_values_table(dataset):\n",
    "#             # Total missing values\n",
    "#             mis_val = dataset.isnull().sum().data(verbose)\n",
    "\n",
    "#             mis_val_percent = 100 * mis_val / len(dataset.data(verbose))\n",
    "\n",
    "#             # Make a table with the results\n",
    "#             mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "#             # Rename the columns\n",
    "#             mis_val_table_ren_columns = mis_val_table.rename(columns={\n",
    "#                 0: 'Missing Values',\n",
    "#                 1: '% of Total Values'\n",
    "#             })\n",
    "#             # Sort the table by percentage of missing descending\n",
    "#             mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "#                 mis_val_table_ren_columns.iloc[:, 1] != 0].sort_values(\n",
    "#                 '% of Total Values', ascending=False).round(1)\n",
    "\n",
    "#             # Print some summary information\n",
    "#             print(\"Your selected dataframe has \" + str(dataset.shape().data(verbose)[1]) + \" columns.\\n\"\n",
    "#                                                                                            \"There are \" + str(\n",
    "#                 mis_val_table_ren_columns.shape[0]) +\n",
    "#                   \" columns that have missing values.\")\n",
    "\n",
    "#             # Return the dataframe with missing information\n",
    "#             return mis_val_table_ren_columns\n",
    "\n",
    "#         missing_values = missing_values_table(app_train)\n",
    "#         missing_values.head(20)\n",
    "\n",
    "#         app_train.dtypes().data(verbose).value_counts()\n",
    "\n",
    "#         app_train.select_dtypes('object').nunique().data(verbose)\n",
    "\n",
    "#         from experiment_graph.sklearn_helper.preprocessing import LabelEncoder\n",
    "#         # Create a label encoder object\n",
    "#         le_count = 0\n",
    "\n",
    "#         columns = app_train.select_dtypes('object').data(verbose).columns\n",
    "#         for col in columns:\n",
    "#             # we are not using nunique because it discard nan\n",
    "#             if app_train[col].nunique(dropna=False).data(verbose) <= 2:\n",
    "#                 le = LabelEncoder()\n",
    "#                 le.fit(app_train[col])\n",
    "\n",
    "#                 app_train = app_train.replace_columns(col, le.transform(app_train[col]))\n",
    "#                 app_test = app_test.replace_columns(col, le.transform(app_test[col]))\n",
    "\n",
    "#                 # Keep track of how many columns were label encoded\n",
    "#                 le_count += 1\n",
    "#         print('%d columns were label encoded.' % le_count)\n",
    "#         app_train.data(verbose)\n",
    "#         app_test.data(verbose)\n",
    "\n",
    "#         app_train = app_train.onehot_encode()\n",
    "#         app_test = app_test.onehot_encode()\n",
    "\n",
    "#         print('Training Features shape: ', app_train.shape().data(verbose))\n",
    "#         print('Testing Features shape: ', app_test.shape().data(verbose))\n",
    "\n",
    "#         train_labels = app_train['TARGET']\n",
    "#         train_columns = app_train.data(verbose).columns\n",
    "#         test_columns = app_test.data(verbose).columns\n",
    "#         for c in train_columns:\n",
    "#             if c not in test_columns:\n",
    "#                 app_train = app_train.drop(c)\n",
    "\n",
    "#         app_train = app_train.add_columns('TARGET', train_labels)\n",
    "\n",
    "#         print('Training Features shape: ', app_train.shape().data(verbose))\n",
    "#         print('Testing Features shape: ', app_test.shape().data(verbose))\n",
    "\n",
    "#         (app_train['DAYS_BIRTH'] / 365).describe().data(verbose)\n",
    "\n",
    "#         app_train['DAYS_EMPLOYED'].describe().data(verbose)\n",
    "\n",
    "#         app_train['DAYS_EMPLOYED'].data(verbose).plot.hist(title='Days Employment Histogram')\n",
    "#         plt.xlabel('Days Employment')\n",
    "\n",
    "#         anom = app_train[app_train['DAYS_EMPLOYED'] == 365243]\n",
    "#         non_anom = app_train[app_train['DAYS_EMPLOYED'] != 365243]\n",
    "#         print('The non-anomalies default on %0.2f%% of loans' % (100 * non_anom['TARGET'].mean().data(verbose)))\n",
    "#         print('The anomalies default on %0.2f%% of loans' % (100 * anom['TARGET'].mean().data(verbose)))\n",
    "#         print('There are %d anomalous days of employment' % anom.shape().data(verbose)[0])\n",
    "\n",
    "#         days_employed_anom = app_train[\"DAYS_EMPLOYED\"] == 365243\n",
    "#         app_train = app_train.add_columns('DAYS_EMPLOYED_ANOM', days_employed_anom)\n",
    "#         temp = app_train['DAYS_EMPLOYED'].replace({365243: np.nan})\n",
    "#         app_train = app_train.drop('DAYS_EMPLOYED')\n",
    "#         app_train = app_train.add_columns('DAYS_EMPLOYED', temp)\n",
    "\n",
    "#         app_train[\"DAYS_EMPLOYED\"].data(verbose).plot.hist(title='Days Employment Histogram');\n",
    "#         plt.xlabel('Days Employment')\n",
    "\n",
    "#         days_employed_anom = app_test[\"DAYS_EMPLOYED\"] == 365243\n",
    "#         app_test = app_test.add_columns('DAYS_EMPLOYED_ANOM', days_employed_anom)\n",
    "#         temp = app_test['DAYS_EMPLOYED'].replace({365243: np.nan})\n",
    "#         app_test = app_test.drop('DAYS_EMPLOYED')\n",
    "#         app_test = app_test.add_columns('DAYS_EMPLOYED', temp)\n",
    "#         print('There are %d anomalies in the test data out of %d entries'\n",
    "#               % (app_test['DAYS_EMPLOYED_ANOM'].sum().data(verbose),\n",
    "#                  app_test.shape().data(verbose)[0]))\n",
    "\n",
    "#         correlations = app_train.corr().data(verbose)\n",
    "#         top = correlations['TARGET'].sort_values()\n",
    "#         # Display correlations\n",
    "#         print('Most Positive Correlations:\\n', top.tail(15))\n",
    "#         print('\\nMost Negative Correlations:\\n', top.head(15))\n",
    "\n",
    "#         abs_age = app_train['DAYS_BIRTH'].abs()\n",
    "#         app_train = app_train.drop('DAYS_BIRTH')\n",
    "#         app_train = app_train.add_columns('DAYS_BIRTH', abs_age)\n",
    "#         app_train['DAYS_BIRTH'].corr(app_train['TARGET']).data(verbose)\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ROOT = '/Users/bede01/Documents/work/phd-papers/ml-workload-optimization'\n",
    "    ROOT_PACKAGE = '/Users/bede01/Documents/work/phd-papers/ml-workload-optimization/code/collaborative-optimizer'\n",
    "\n",
    "    import sys\n",
    "\n",
    "    sys.path.append(ROOT_PACKAGE)\n",
    "    from experiment_graph.data_storage import DedupedStorageManager\n",
    "    from experiment_graph.executor import CollaborativeExecutor, HelixExecutor\n",
    "    from experiment_graph.execution_environment import ExecutionEnvironment\n",
    "    from experiment_graph.optimizations.Reuse import LinearTimeReuse\n",
    "    from experiment_graph.materialization_algorithms.materialization_methods import AllMaterializer, HelixMaterializer\n",
    "\n",
    "    workload = start_here_a_gentle_introduction()\n",
    "\n",
    "    mat_budget = 0.001 * 1024.0 * 1024.0\n",
    "    sa_materializer = HelixMaterializer(storage_budget=mat_budget)\n",
    "\n",
    "    # ee = ExecutionEnvironment(DedupedStorageManager(), reuse_type=LinearTimeReuse.NAME)\n",
    "\n",
    "    root_data = ROOT + '/data'\n",
    "    # database_path = \\\n",
    "    #     root_data + '/experiment_graphs/kaggle_home_credit/start_here_a_gentle_introduction/all_mat'\n",
    "    # if os.path.exists(database_path):\n",
    "    #     ee.load_history_from_disk(database_path)\n",
    "\n",
    "    executor = HelixExecutor(budget=mat_budget)\n",
    "    execution_start = datetime.now()\n",
    "\n",
    "    executor.end_to_end_run(workload=workload, root_data=root_data, verbose=1)\n",
    "    # executor.store_experiment_graph(database_path)\n",
    "    execution_end = datetime.now()\n",
    "    elapsed = (execution_end - execution_start).total_seconds()\n",
    "\n",
    "    print('finished execution in {} seconds'.format(elapsed))\n",
    "    print('running again')\n",
    "    executor.end_to_end_run(workload=workload, root_data=root_data, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'885517FA12002C9EFFCF2618E23CEB6C'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workload = executor.execution_environment.workload_dag\n",
    "experiment_graph = executor.execution_environment.experiment_graph.graph\n",
    "vertex = '885517FA12002C9EFFCF2618E23CEB6C'\n",
    "vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executor.execution_environment.experiment_graph.plot_graph(plt, figsize=(20,50), labels_for_vertex=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'885517FA12002C9EFFCF2618E23CEB6C'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5c5154f3d36d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mworkload_subgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_execution_subgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvertex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0munified_problem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHelixReuse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munify_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkload_subgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplot_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munified_problem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0munified_problem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bede01/Documents/work/phd-papers/ml-workload-optimization/code/collaborative-optimizer/experiment_graph/graph/graph_representations.pyc\u001b[0m in \u001b[0;36mcompute_execution_subgraph\u001b[0;34m(self, vertex)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mexecution_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mvertex\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvertex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             \u001b[0mprevs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredecessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/networkx/classes/reportviews.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m# Set methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '885517FA12002C9EFFCF2618E23CEB6C'"
     ]
    }
   ],
   "source": [
    "workload_subgraph = workload.compute_execution_subgraph(vertex)\n",
    "unified_problem = HelixReuse().unify_graph(workload_subgraph, experiment_graph, vertex)\n",
    "plot_graph(graph=unified_problem, prog='dot')\n",
    "unified_problem.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psp_graph = HelixReuse().workload_graph_to_psp(unified_problem)\n",
    "plot_graph(figsize=(50,10), graph=psp_graph, prog='dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openml import datasets, tasks, runs, flows, setups, config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "config.apikey = '8e2079508005379adb9a60798696134e'\n",
    "config.server = 'https://www.openml.org/api/v1'\n",
    "config.set_cache_directory(os.path.expanduser('~/openml-cache'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select and filter flows made by scikit learn\n",
    "flowsJson = flows.list_flows()\n",
    "flowList = pd.DataFrame.from_dict(flowsJson, orient='index')[['id','name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Template\n",
    "A pipeline template contains information about the created pipelines in the framework. \n",
    "It contains an id, name, list of transformations, the model, and the framework the pipeline is desgined in.\n",
    "The pipeline tempalte does not indicate an actual trained pipeline, it is the architecture of the pipeline.\n",
    "\n",
    "To Do:\n",
    "- Extract Model name from the data\n",
    "- Extract a list of parameter names for the Pipeline Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = flowList.loc[flowList.name.str.startswith('sklearn.pipeline')]\n",
    "pipelines = pipelines.assign(parsed = pipelines.name.map(lambda x: x[x.find('(') + 1:x.find(')') + 1]).map(lambda s : s.split(',')))\n",
    "pipelines = pipelines.assign(p_length = pipelines.parsed.map(lambda p: len(p)))\n",
    "pipelines = pipelines.query('p_length > 1')\n",
    "pipelines.parsed = pipelines.parsed.map(lambda pi : map(lambda p: p[p.find('=') + 1 :], pi))\n",
    "pipelines.parsed = pipelines.parsed.map(lambda pi : map(lambda p: p.strip('()'), pi))\n",
    "PipelineTemplate = pipelines[['id','name','parsed']].rename(columns = {'parsed':'transfromations'})\n",
    "# We are only supporting scikit learn for now\n",
    "PipelineTemplate['framework']='sklearn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>transfromations</th>\n",
       "      <th>framework</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>5432</td>\n",
       "      <td>sklearn.pipeline.Pipeline(sklearn.preprocessin...</td>\n",
       "      <td>[sklearn.preprocessing.imputation.Imputer, skl...</td>\n",
       "      <td>sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5505</th>\n",
       "      <td>5505</td>\n",
       "      <td>sklearn.pipeline.Pipeline(steps__scale=sklearn...</td>\n",
       "      <td>[sklearn.preprocessing.data.RobustScaler, skle...</td>\n",
       "      <td>sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5507</th>\n",
       "      <td>5507</td>\n",
       "      <td>sklearn.pipeline.Pipeline(steps__imputer=sklea...</td>\n",
       "      <td>[sklearn.preprocessing.imputation.Imputer, skl...</td>\n",
       "      <td>sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5520</th>\n",
       "      <td>5520</td>\n",
       "      <td>sklearn.pipeline.Pipeline(steps__Imputer=sklea...</td>\n",
       "      <td>[sklearn.preprocessing.imputation.Imputer, skl...</td>\n",
       "      <td>sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5591</th>\n",
       "      <td>5591</td>\n",
       "      <td>sklearn.pipeline.Pipeline(Imputer=sklearn.prep...</td>\n",
       "      <td>[sklearn.preprocessing.imputation.Imputer, skl...</td>\n",
       "      <td>sklearn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               name  \\\n",
       "5432  5432  sklearn.pipeline.Pipeline(sklearn.preprocessin...   \n",
       "5505  5505  sklearn.pipeline.Pipeline(steps__scale=sklearn...   \n",
       "5507  5507  sklearn.pipeline.Pipeline(steps__imputer=sklea...   \n",
       "5520  5520  sklearn.pipeline.Pipeline(steps__Imputer=sklea...   \n",
       "5591  5591  sklearn.pipeline.Pipeline(Imputer=sklearn.prep...   \n",
       "\n",
       "                                        transfromations framework  \n",
       "5432  [sklearn.preprocessing.imputation.Imputer, skl...   sklearn  \n",
       "5505  [sklearn.preprocessing.data.RobustScaler, skle...   sklearn  \n",
       "5507  [sklearn.preprocessing.imputation.Imputer, skl...   sklearn  \n",
       "5520  [sklearn.preprocessing.imputation.Imputer, skl...   sklearn  \n",
       "5591  [sklearn.preprocessing.imputation.Imputer, skl...   sklearn  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PipelineTemplate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Log\n",
    "Contains a log every execution training.\n",
    "To simply and reduce size, exact duplicates are marked with a counts parameter at every row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_LOGS_LOC = '../../data/training-logs.csv'\n",
    "def readOrDownloadLogs():\n",
    "    if (os.path.exists(TRAINING_LOGS_LOC)):\n",
    "        training_logs_table = pd.read_csv(TRAINING_LOGS_LOC)\n",
    "        return (training_logs_table)\n",
    "    else:\n",
    "        size = 10000\n",
    "        offset = 0\n",
    "        rl = runs.list_runs(flow=flow_ids, size = size, offset = offset)\n",
    "        experiments = pd.DataFrame.from_dict(rl, orient='index')\n",
    "        try:\n",
    "            while(0 < 1):\n",
    "                offset = offset + size\n",
    "                rl = runs.list_runs(flow=flow_ids, size = size, offset = offset)\n",
    "                experiments = appendRun(experiments, rl)\n",
    "        except Exception:\n",
    "            print('finished reading')\n",
    "        training_logs_table = experiments.groupby(['setup_id', 'flow_id','task_id']).size().reset_index(name='counts')\n",
    "        training_logs_table.to_csv(TRAINING_LOGS_LOC, index=False)\n",
    "        return (training_logs_table)\n",
    "\n",
    "TrainingLog = readOrDownloadLogs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setup_id</th>\n",
       "      <th>flow_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29246</td>\n",
       "      <td>5591</td>\n",
       "      <td>59</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29288</td>\n",
       "      <td>5653</td>\n",
       "      <td>145677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29293</td>\n",
       "      <td>5662</td>\n",
       "      <td>145677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29294</td>\n",
       "      <td>5663</td>\n",
       "      <td>145677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30231</td>\n",
       "      <td>5743</td>\n",
       "      <td>145677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   setup_id  flow_id  task_id  counts\n",
       "0     29246     5591       59      23\n",
       "1     29288     5653   145677       1\n",
       "2     29293     5662   145677       1\n",
       "3     29294     5663   145677       1\n",
       "4     30231     5743   145677       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainingLog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskIds = TrainingLog.task_id.unique()\n",
    "flowIds = TrainingLog.flow_id.unique()\n",
    "setupIds = TrainingLog.setup_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPING_LOC = '../../data/mapping.csv'\n",
    "def readOrDownloadMapping():\n",
    "    if (os.path.exists(MAPPING_LOC)):\n",
    "        mapping_table = pd.read_csv(MAPPING_LOC)\n",
    "        return (mapping_table)\n",
    "    else:\n",
    "        taskList = []\n",
    "        for t in taskIds:\n",
    "            #print 'retreiving task: ' + str(t)\n",
    "            try:\n",
    "                task = tasks.get_tasks(task_ids=[t])\n",
    "                taskList.append(task)\n",
    "            except Exception:\n",
    "                print 'error in task: ' + str (t)\n",
    "        datasetIds = []\n",
    "        mapping = dict()\n",
    "        for t in taskList:\n",
    "            mapping[t[0].task_id] = (t[0].dataset_id) \n",
    "\n",
    "        # mapping table to change the task id in Pipeline table to dataset\n",
    "        mapping_table = pd.DataFrame.from_dict(mapping,orient='index')\n",
    "        mapping_table['task'] = mapping_table.index\n",
    "        mapping_table = mapping_table.rename(columns = {0:'dataset'})\n",
    "        mapping_table.to_csv(MAPPING_LOC, index=False)\n",
    "    return (mapping_table)\n",
    "    \n",
    "Mapping = readOrDownloadMapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  task\n",
       "0        1     1\n",
       "1        2     2\n",
       "2        4     4\n",
       "3        5     5\n",
       "4        6     6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mapping.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Table\n",
    "A pipeline, as opposed to a pipeline template, is a concrete pipeline that is trained on a specific dataset with a set of hyperparameters (with values) and transformations.\n",
    "It has an id, id of the pipeline template, a setup id (indicating the list of parameters and their values), and a dataset id.\n",
    "\n",
    "To Do:\n",
    "- There still multiple instances of a Pipeline Template and Dataset that have different setup id. We need to investigate whether, different setup ids always indicate different setup of parameter values or it is possible that the parameter values are the same for some of the setup ids. In that case we should remove the duplicate setup ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = TrainingLog[['flow_id','setup_id','task_id']]\\\n",
    "    .merge(Mapping, left_on = 'task_id', right_on ='task')[['flow_id','dataset','setup_id']]\\\n",
    "    .drop_duplicates()\n",
    "p['id'] = p.apply(lambda i : str(i[0])+str(i[1])+str(i[2]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipeline = p.rename(columns={'flow_id':'pipeline_template', 'setup_id':'setup'})[['id','pipeline_template','setup','dataset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pEquals(p1, p2):\n",
    "    if p1.data_type != p2.data_type or\\\n",
    "    p1.default_value != p2.default_value or\\\n",
    "    p1.flow_id != p2.flow_id or\\\n",
    "    p1.full_name != p2.full_name or\\\n",
    "    p1.id != p2.id or\\\n",
    "    p1.parameter_name != p2.parameter_name or\\\n",
    "    p1.value != p2.value:\n",
    "        return False\n",
    "    else:\n",
    "        return True \n",
    "    \n",
    "def sEquals(s1,s2):\n",
    "    if len(s1.parameters) != len(s1.parameters):\n",
    "        return False\n",
    "    elif s1.parameters.keys() != s2.parameters.keys():\n",
    "        return False\n",
    "    else:\n",
    "        for k in s1.parameters.keys():\n",
    "            p1 = s1.parameters.get(k)\n",
    "            p2 = s2.parameters.get(k)\n",
    "            if not pEquals(p1,p2):\n",
    "                return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation Template Table \n",
    "The transformation table includes the information about specific transformations, their parameters, and the framework the belong to. This is table contains the static information about the Transformations.\n",
    "\n",
    "To Do:\n",
    "- Extract list of parameters for each Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTransformations = set()\n",
    "PipelineTemplate.transfromations.map(lambda ts : [allTransformations.add(a) for a in ts])\n",
    "Transformation = pd.DataFrame(list(allTransformations), columns=['name'])\n",
    "Transformation['id'] = Transformation.index\n",
    "Transformation['framework']='sklearn'\n",
    "Transformation['parameters'] = \"\"\n",
    "Transformation = Transformation[['id','name','parameters','framework']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>parameters</th>\n",
       "      <th>framework</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>__main__.LightClassifier</td>\n",
       "      <td></td>\n",
       "      <td>sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sklearn.ensemble.voting_classifier.VotingClass...</td>\n",
       "      <td></td>\n",
       "      <td>sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sklearn.ensemble.voting_classifier.VotingClass...</td>\n",
       "      <td></td>\n",
       "      <td>sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>sklearn.neural_network.multilayer_perceptron.M...</td>\n",
       "      <td></td>\n",
       "      <td>sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>sklearn.ensemble.voting_classifier.VotingClass...</td>\n",
       "      <td></td>\n",
       "      <td>sklearn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               name parameters framework\n",
       "0   0                           __main__.LightClassifier              sklearn\n",
       "1   1  sklearn.ensemble.voting_classifier.VotingClass...              sklearn\n",
       "2   2  sklearn.ensemble.voting_classifier.VotingClass...              sklearn\n",
       "3   3  sklearn.neural_network.multilayer_perceptron.M...              sklearn\n",
       "4   4  sklearn.ensemble.voting_classifier.VotingClass...              sklearn"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Transformation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Table\n",
    "The parameter table contains a list of all the parameters, (their type information), and their default values.\n",
    "The current version only support transformation available in scikit-learn Currently, the table has the following format:\n",
    "\n",
    "|id            | name     | full_name | default_value | type |\n",
    "|:------------ |:--------------|:------|:----------------|:----------------|\n",
    "|id |  name| Full Name| Default value|Type information|\n",
    "\n",
    "TODO:\n",
    "- Ensure that all that every setup for a specific flow has the exact same set of parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETER_LOC = '../../data/parameter.csv'\n",
    "def readOrDownloadParams():\n",
    "    if (os.path.exists(PARAMETER_LOC)):\n",
    "        parameter_table = pd.read_csv(PARAMETER_LOC)\n",
    "        return (parameter_table)\n",
    "    else:\n",
    "        # have to check these to make sure that every setup for a flow contains exactly the same set of parameters\n",
    "        all_setups = Pipeline[['pipeline_template','setup']]\n",
    "        unique_parameters = all_setups.drop_duplicates(subset=['pipeline_template'])\n",
    "        all_setups = setups.list_setups(setup=unique_parameters.setup)\n",
    "        parameter_table = pd.DataFrame(columns=['id','name','full_name','default_value','type'])\n",
    "        for sk, sv in all_setups.iteritems():\n",
    "            for pk, pv in sv.parameters.iteritems():\n",
    "                parameter_table.loc[parameter_table.shape[0]] = [pv.id,pv.parameter_name,pv.full_name,pv.default_value,pv.data_type]\n",
    "        parameter_table.to_csv(PARAMETER_LOC, index=False)\n",
    "        return (parameter_table)\n",
    "    \n",
    "Parameter = readOrDownloadParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>default_value</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53952</td>\n",
       "      <td>iterated_power</td>\n",
       "      <td>sklearn.decomposition.pca.PCA(1)_iterated_power</td>\n",
       "      <td>\"auto\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53953</td>\n",
       "      <td>n_components</td>\n",
       "      <td>sklearn.decomposition.pca.PCA(1)_n_components</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53954</td>\n",
       "      <td>random_state</td>\n",
       "      <td>sklearn.decomposition.pca.PCA(1)_random_state</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53955</td>\n",
       "      <td>svd_solver</td>\n",
       "      <td>sklearn.decomposition.pca.PCA(1)_svd_solver</td>\n",
       "      <td>\"auto\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53956</td>\n",
       "      <td>tol</td>\n",
       "      <td>sklearn.decomposition.pca.PCA(1)_tol</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            name                                        full_name  \\\n",
       "0  53952  iterated_power  sklearn.decomposition.pca.PCA(1)_iterated_power   \n",
       "1  53953    n_components    sklearn.decomposition.pca.PCA(1)_n_components   \n",
       "2  53954    random_state    sklearn.decomposition.pca.PCA(1)_random_state   \n",
       "3  53955      svd_solver      sklearn.decomposition.pca.PCA(1)_svd_solver   \n",
       "4  53956             tol             sklearn.decomposition.pca.PCA(1)_tol   \n",
       "\n",
       "  default_value  type  \n",
       "0        \"auto\"   NaN  \n",
       "1           NaN   NaN  \n",
       "2           NaN   NaN  \n",
       "3        \"auto\"   NaN  \n",
       "4           0.0   NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parameter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Table\n",
    "The Dataset table contains metadata about the existing datasets in the training runs.\n",
    "First from the pipeline table, the tasks are extracted, then the correspoding dataset is retreived from OpenML.\n",
    "The table has the following schema:\n",
    "\n",
    "|id            | name     | NumberOfClasses | NumberOfFeatures | NumberOfInstances |\n",
    "|:------------ |:--------------|:------|:----------------|:----------------|\n",
    "|id |  name| Number of classes| Number of Features |Number of training instances|\n",
    "\n",
    "TODO:\n",
    "- OpenML contains more information about the Datasets, check if any other information are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_LOC = '../../data/dataset.csv'\n",
    "def readOrDownloadDatasets():\n",
    "    if (os.path.exists(DATASET_LOC)):\n",
    "        dataset_table = pd.read_csv(DATASET_LOC)\n",
    "        return (dataset_table)\n",
    "    else:\n",
    "        ds = datasets.list_datasets()\n",
    "        datasetTable = pd.DataFrame.from_dict(ds, orient='index')\n",
    "        existingDatasets = datasetTable[datasetTable.did.isin(Mapping.dataset.unique())]\n",
    "        dataset_table = existingDatasets.rename(columns = {\"did\":\"id\"})[['id','name', 'NumberOfClasses','NumberOfFeatures','NumberOfInstances']]\n",
    "        dataset_table.to_csv(DATASET_LOC, index=False)\n",
    "        return (dataset_table)\n",
    "Dataset = readOrDownloadDatasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>NumberOfClasses</th>\n",
       "      <th>NumberOfFeatures</th>\n",
       "      <th>NumberOfInstances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>anneal</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>labor</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>arrhythmia</td>\n",
       "      <td>13</td>\n",
       "      <td>280</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>letter</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>lymph</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        name  NumberOfClasses  NumberOfFeatures  NumberOfInstances\n",
       "0   2      anneal                5                39                898\n",
       "1   4       labor                2                17                 57\n",
       "2   5  arrhythmia               13               280                452\n",
       "3   6      letter               26                17              20000\n",
       "4  10       lymph                4                19                148"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Table\n",
    "An intermediary table that comes between the Pipeline and the Parameter table. Each entry in the Setup Id is mapped to on entry in the Pipeline table and includes a list of all the parameters and their (run time) values for that specific instance of the Pipeline exeuction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SETUP_LOC = '../../data/setups.csv'\n",
    "def readOrDownloadSetups():\n",
    "    if (os.path.exists(SETUP_LOC)):\n",
    "        setup_table = pd.read_csv(SETUP_LOC)\n",
    "        return (setup_table)\n",
    "    setup_table = pd.DataFrame(columns=['id','pipeline','parameters'])\n",
    "    size = 100\n",
    "    offset = 0\n",
    "    setup_dict = setups.list_setups(setup = setupIds[offset:(offset+size)])\n",
    "    for s in setup_dict.values():\n",
    "        params = dict()\n",
    "        for k,v in s.parameters.iteritems():\n",
    "            params[k] = v.value\n",
    "        setup_table.loc[setup_table.shape[0]] = [s.setup_id, s.flow_id, params]\n",
    "    try:\n",
    "        while(0 < 1):\n",
    "            offset = offset + size\n",
    "            setup_dict = setups.list_setups(setup = setupIds[offset:(offset+size)])\n",
    "            for s in setup_dict.values():\n",
    "                params = dict()\n",
    "                for k,v in s.parameters.iteritems():\n",
    "                    params[k] = v.value\n",
    "                setup_table.loc[setup_table.shape[0]] = [s.setup_id, s.flow_id, params]\n",
    "    except Exception:\n",
    "        print('finished reading')\n",
    "    setup_table.to_csv(SETUP_LOC, index=False)\n",
    "    return (setup_table)\n",
    "\n",
    "Setup = readOrDownloadSetups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Setup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deduplication of Setup ids\n",
    "Here we attempt to deduplicate any configuration setup (for same pipeline) that has exactly the same parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A setup configuration cannot belong to multiple pipelines\n",
    "assert Setup.shape[0] == len(Setup.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure every pipeline has exactly the same set of parameters keys(values are obviously are not always the same)\n",
    "a = Setup.groupby('pipeline').apply(lambda x: (len(x.parameters.keys()) - len(set(x.parameters.keys())))).reset_index(name = 'size')\n",
    "assert a['size'].max() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

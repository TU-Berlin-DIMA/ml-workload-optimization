{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openml import datasets, tasks, runs, flows, setups, config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "config.apikey = '8e2079508005379adb9a60798696134e'\n",
    "config.server = 'https://www.openml.org/api/v1'\n",
    "config.set_cache_directory(os.path.expanduser('~/openml-cache'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select and filter flows made by scikit learn\n",
    "flowsJson = flows.list_flows()\n",
    "flowList = pd.DataFrame.from_dict(flowsJson, orient='index')[['id','name']]\n",
    "pipelines = flowList.loc[flowList.name.str.startswith('sklearn.pipeline')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse pipelines and find valid pipelines \n",
    "pipelines = pipelines.assign(parsed = pipelines.name.map(lambda x: x[x.find('(') + 1:x.find(')') + 1]).map(lambda s : s.split(',')))\n",
    "pipelines = pipelines.assign(p_length = pipelines.parsed.map(lambda p: len(p)))\n",
    "pipelines = pipelines.query('p_length > 1')\n",
    "#pipelines.drop(['name'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove step names and extra punctuations\n",
    "pipelines.parsed = pipelines.parsed.map(lambda pi : map(lambda p: p[p.find('=') + 1 :], pi))\n",
    "pipelines.parsed = pipelines.parsed.map(lambda pi : map(lambda p: p.strip('()'), pi))\n",
    "flow_ids = pipelines.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendRun(df, nextBatch):\n",
    "    nb = pd.DataFrame.from_dict(nextBatch, orient='index')\n",
    "    return (pd.concat([df,nb]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_RUNS_LOC = '../../data/training-runs.csv'\n",
    "def readOrDownloadRuns():\n",
    "    if (os.path.exists(TRAINING_RUNS_LOC)):\n",
    "        trainingRuns = pd.read_csv(TRAINING_RUNS_LOC)\n",
    "        return (trainingRuns)\n",
    "    else:\n",
    "        size = 10000\n",
    "        offset = 0\n",
    "        rl = runs.list_runs(flow=flow_ids, size = size, offset = offset)\n",
    "        experiments = pd.DataFrame.from_dict(rl, orient='index')\n",
    "        try:\n",
    "            while(0 < 1):\n",
    "                offset = offset + size\n",
    "                rl = runs.list_runs(flow=flow_ids, size = size, offset = offset)\n",
    "                experiments = appendRun(experiments, rl)\n",
    "        except Exception:\n",
    "            print('finished reading')\n",
    "        trainingRuns = experiments.groupby(['setup_id', 'flow_id','task_id']).size().reset_index(name='counts')\n",
    "        trainingRuns.to_csv(TRAINING_RUNS_LOC, index=False)\n",
    "        return (trainingRuns)\n",
    "\n",
    "trainingRuns = readOrDownloadRuns()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setup_id</th>\n",
       "      <th>flow_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29246</td>\n",
       "      <td>5591</td>\n",
       "      <td>59</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29288</td>\n",
       "      <td>5653</td>\n",
       "      <td>145677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29293</td>\n",
       "      <td>5662</td>\n",
       "      <td>145677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29294</td>\n",
       "      <td>5663</td>\n",
       "      <td>145677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30231</td>\n",
       "      <td>5743</td>\n",
       "      <td>145677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   setup_id  flow_id  task_id  counts\n",
       "0     29246     5591       59      23\n",
       "1     29288     5653   145677       1\n",
       "2     29293     5662   145677       1\n",
       "3     29294     5663   145677       1\n",
       "4     30231     5743   145677       1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingRuns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskIds = trainingRuns.task_id.unique()\n",
    "flowIds = trainingRuns.flow_id.unique()\n",
    "setupIds = trainingRuns.setup_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = pipelines.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation Table\n",
    "The Transformation table include the list of all the available transformations.\n",
    "The current version only support transformation available in scikit-learn\n",
    "Currently, the table has the following format:\n",
    "\n",
    "|id            | full_name     |\n",
    "|:------------ |:--------------|\n",
    "|id of the Transformation| Full name of the Transformation|\n",
    "\n",
    "TODO:\n",
    "- For each transformation, extract the required parameters as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all different transformations from the trainingRuns table\n",
    "# investiage training runs and the pipeline table do not have matching flow (pipeline) ids\n",
    "# even though the training run is queried from pipeline id column\n",
    "currentPipelines = pipelines[pipelines.id.isin(flowIds)].reset_index(drop=True)\n",
    "allTrasformations = []\n",
    "currentPipelines.parsed.map(lambda ts : [allTrasformations.append(a) for a in ts])\n",
    "transformations = pd.DataFrame(allTrasformations, columns=['full_name'])\n",
    "Transformation = pd.DataFrame({'id': transformations.full_name.unique(), 'full_name': transformations.full_name.unique()}, columns = ['id','full_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>parsed</th>\n",
       "      <th>p_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5432</td>\n",
       "      <td>sklearn.pipeline.Pipeline(sklearn.preprocessin...</td>\n",
       "      <td>[sklearn.preprocessing.imputation.Imputer, skl...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5505</td>\n",
       "      <td>sklearn.pipeline.Pipeline(steps__scale=sklearn...</td>\n",
       "      <td>[sklearn.preprocessing.data.RobustScaler, skle...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5507</td>\n",
       "      <td>sklearn.pipeline.Pipeline(steps__imputer=sklea...</td>\n",
       "      <td>[sklearn.preprocessing.imputation.Imputer, skl...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5520</td>\n",
       "      <td>sklearn.pipeline.Pipeline(steps__Imputer=sklea...</td>\n",
       "      <td>[sklearn.preprocessing.imputation.Imputer, skl...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5591</td>\n",
       "      <td>sklearn.pipeline.Pipeline(Imputer=sklearn.prep...</td>\n",
       "      <td>[sklearn.preprocessing.imputation.Imputer, skl...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               name  \\\n",
       "0  5432  sklearn.pipeline.Pipeline(sklearn.preprocessin...   \n",
       "1  5505  sklearn.pipeline.Pipeline(steps__scale=sklearn...   \n",
       "2  5507  sklearn.pipeline.Pipeline(steps__imputer=sklea...   \n",
       "3  5520  sklearn.pipeline.Pipeline(steps__Imputer=sklea...   \n",
       "4  5591  sklearn.pipeline.Pipeline(Imputer=sklearn.prep...   \n",
       "\n",
       "                                              parsed  p_length  \n",
       "0  [sklearn.preprocessing.imputation.Imputer, skl...         3  \n",
       "1  [sklearn.preprocessing.data.RobustScaler, skle...         2  \n",
       "2  [sklearn.preprocessing.imputation.Imputer, skl...         4  \n",
       "3  [sklearn.preprocessing.imputation.Imputer, skl...         3  \n",
       "4  [sklearn.preprocessing.imputation.Imputer, skl...         3  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Table\n",
    "The Pipeline table contains information about the pipeline, consists of the model, the transformations, the dataset the pipeline is trained on, and parameters. \n",
    "The current version only support transformation available in scikit-learn Currently, the table has the following format:\n",
    "\n",
    "|id            | full_name     | model | transformations | hyperparameters | dataset |\n",
    "|:------------ |:--------------|:------|:----------------|:----------------|---------|\n",
    "|id | Full name| List of Transformations| learned model|hyper parameters of the transformations and the model| dataset|\n",
    "\n",
    "TODO:\n",
    "- Extract model\n",
    "- Extract hyperparameters\n",
    "- There are multiple setup ids for some combinatino of <flow,task>. Make sure that only the parameter values are different and not the actual parameter names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the pipeline info from the run and flow tables\n",
    "currentPipelines = pipelines[pipelines.id.isin(flowIds)].reset_index(drop=True)\n",
    "# Check the setup ids later. for now just ignore setup_id \n",
    "joined = currentPipelines.merge(trainingRuns, left_on='id', right_on='flow_id')[['id','name','task_id','parsed']]\n",
    "dedulicated = before.drop_duplicates(subset=['id','task_id'])\n",
    "Pipeline = dedulicated.rename(columns = {\"name\":\"full_name\", \"parsed\":\"transformations\", \"task_id\":\"dataset\"})[['id','full_name','transformations','dataset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_name</th>\n",
       "      <th>transformations</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5591</td>\n",
       "      <td>sklearn.pipeline.Pipeline(Imputer=sklearn.prep...</td>\n",
       "      <td>[sklearn.preprocessing.imputation.Imputer, skl...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5648</td>\n",
       "      <td>sklearn.pipeline.Pipeline(Imputer=openml.utils...</td>\n",
       "      <td>[openml.utils.preprocessing.ConditionalImputer...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5653</td>\n",
       "      <td>sklearn.pipeline.Pipeline(feature_select=sklea...</td>\n",
       "      <td>[sklearn.feature_selection.univariate_selectio...</td>\n",
       "      <td>145677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5662</td>\n",
       "      <td>sklearn.pipeline.Pipeline(scaling=sklearn.prep...</td>\n",
       "      <td>[sklearn.preprocessing.data.StandardScaler, sk...</td>\n",
       "      <td>145677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5663</td>\n",
       "      <td>sklearn.pipeline.Pipeline(scaling=sklearn.prep...</td>\n",
       "      <td>[sklearn.preprocessing.data.StandardScaler, sk...</td>\n",
       "      <td>145677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                          full_name  \\\n",
       "0  5591  sklearn.pipeline.Pipeline(Imputer=sklearn.prep...   \n",
       "2  5648  sklearn.pipeline.Pipeline(Imputer=openml.utils...   \n",
       "3  5653  sklearn.pipeline.Pipeline(feature_select=sklea...   \n",
       "4  5662  sklearn.pipeline.Pipeline(scaling=sklearn.prep...   \n",
       "5  5663  sklearn.pipeline.Pipeline(scaling=sklearn.prep...   \n",
       "\n",
       "                                     transformations  dataset  \n",
       "0  [sklearn.preprocessing.imputation.Imputer, skl...       59  \n",
       "2  [openml.utils.preprocessing.ConditionalImputer...       29  \n",
       "3  [sklearn.feature_selection.univariate_selectio...   145677  \n",
       "4  [sklearn.preprocessing.data.StandardScaler, sk...   145677  \n",
       "5  [sklearn.preprocessing.data.StandardScaler, sk...   145677  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pipeline.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Table\n",
    "The parameter table contains a list of all the parameters, (their type information), and their default values.\n",
    "The current version only support transformation available in scikit-learn Currently, the table has the following format:\n",
    "\n",
    "|id            | name     | full_name | default_value | type |\n",
    "|:------------ |:--------------|:------|:----------------|:----------------|\n",
    "|id |  name| Full Name| Default value|Type information|\n",
    "\n",
    "TODO:\n",
    "- Ensure that all that every setup for a specific flow has the exact same set of parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_setups = Pipeline.merge(trainingRuns, left_on='id', right_on='flow_id')[['id','setup_id']]\n",
    "# have to check these to make sure that every setup for a flow contains exactly the same set of parameters\n",
    "unique_parameters = all_setups.drop_duplicates(subset=['id'])\n",
    "all_setups = setups.list_setups(setup=unique_parameters.setup_id)\n",
    "Parameter = pd.DataFrame(columns=['id','name','full_name','default_value','type'])\n",
    "for sk, sv in all_setups.iteritems():\n",
    "    for pk, pv in sv.parameters.iteritems():\n",
    "        df.loc[df.shape[0]] = [pv.id,pv.parameter_name,pv.full_name,pv.default_value,pv.data_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>default_value</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53952</td>\n",
       "      <td>iterated_power</td>\n",
       "      <td>sklearn.decomposition.pca.PCA(1)_iterated_power</td>\n",
       "      <td>\"auto\"</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53953</td>\n",
       "      <td>n_components</td>\n",
       "      <td>sklearn.decomposition.pca.PCA(1)_n_components</td>\n",
       "      <td>null</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53954</td>\n",
       "      <td>random_state</td>\n",
       "      <td>sklearn.decomposition.pca.PCA(1)_random_state</td>\n",
       "      <td>null</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53955</td>\n",
       "      <td>svd_solver</td>\n",
       "      <td>sklearn.decomposition.pca.PCA(1)_svd_solver</td>\n",
       "      <td>\"auto\"</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53956</td>\n",
       "      <td>tol</td>\n",
       "      <td>sklearn.decomposition.pca.PCA(1)_tol</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            name                                        full_name  \\\n",
       "0  53952  iterated_power  sklearn.decomposition.pca.PCA(1)_iterated_power   \n",
       "1  53953    n_components    sklearn.decomposition.pca.PCA(1)_n_components   \n",
       "2  53954    random_state    sklearn.decomposition.pca.PCA(1)_random_state   \n",
       "3  53955      svd_solver      sklearn.decomposition.pca.PCA(1)_svd_solver   \n",
       "4  53956             tol             sklearn.decomposition.pca.PCA(1)_tol   \n",
       "\n",
       "  default_value  type  \n",
       "0        \"auto\"  None  \n",
       "1          null  None  \n",
       "2          null  None  \n",
       "3        \"auto\"  None  \n",
       "4           0.0  None  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parameter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.list_datasets()\n",
    "datasetTable = pd.DataFrame.from_dict(ds, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "relatedTasks = Pipeline.dataset.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    59,     29, 145677,   9893,     58,   3512,   3918,  10093,\n",
       "         9986,      1,      3,      6,     10,     11,     12,     14,\n",
       "           16,     18,     20,     21,     22,     23,     26,     28,\n",
       "           30,     31,     32,     36,     37,     38,     39,     40,\n",
       "           42,     43,     45,     47,     49,     52,     53,     57,\n",
       "           60,    206,    219,    231,    233,    236,    240,    241,\n",
       "          242,    244,    246,    248,    250,    251,    252,    256,\n",
       "         9983, 125923,   3917,   9980,   3902,  34539,      2,     15,\n",
       "           24,     41,   2074,   2075,   2079,   3021,   3022,   3481,\n",
       "         3485,   3492,   3493,   3494,   3510,   3543,   3549,   3560,\n",
       "         3561,   3567,   3889,   3891,   3896,   3899,   3903,   3904,\n",
       "         3913,   3946,   3948,   3950,   3954,   7592,   9914,   9946,\n",
       "         9950,   9952,   9954,   9955,   9956,   9957,   9960,   9964,\n",
       "         9967,   9968,   9970,   9971,   9976,   9977,   9978,   9979,\n",
       "         9981,   9985,  10101,  14964,  14965,  14966,  14967,  14968,\n",
       "        14969,  14970,  14971,  34536,  34537,  34538, 125920, 125921,\n",
       "       125922,   2071,   3647, 146607,   3573, 146606, 146195,      5,\n",
       "            4,      7,  14951,  10103])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relatedTasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tasks.get_tasks(task_ids=[59])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dataset_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    59,     29, 145677,   9893,     58,   3512,   3918,  10093,\n",
       "         9986,      1,      3,      6,     10,     11,     12,     14,\n",
       "           16,     18,     20,     21,     22,     23,     26,     28,\n",
       "           30,     31,     32,     36,     37,     38,     39,     40,\n",
       "           42,     43,     45,     47,     49,     52,     53,     57,\n",
       "           60,    206,    219,    231,    233,    236,    240,    241,\n",
       "          242,    244,    246,    248,    250,    251,    252,    256,\n",
       "         9983, 125923,   3917,   9980,   3902,  34539,      2,     15,\n",
       "           24,     41,   2074,   2075,   2079,   3021,   3022,   3481,\n",
       "         3485,   3492,   3493,   3494,   3510,   3543,   3549,   3560,\n",
       "         3561,   3567,   3889,   3891,   3896,   3899,   3903,   3904,\n",
       "         3913,   3946,   3948,   3950,   3954,   7592,   9914,   9946,\n",
       "         9950,   9952,   9954,   9955,   9956,   9957,   9960,   9964,\n",
       "         9967,   9968,   9970,   9971,   9976,   9977,   9978,   9979,\n",
       "         9981,   9985,  10101,  14964,  14965,  14966,  14967,  14968,\n",
       "        14969,  14970,  14971,  34536,  34537,  34538, 125920, 125921,\n",
       "       125922,   2071,   3647, 146607,   3573, 146606, 146195,      5,\n",
       "            4,      7,  14951,  10103])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relatedTasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

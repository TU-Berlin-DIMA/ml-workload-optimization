{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openml import datasets, tasks, runs, flows, setups, config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "config.apikey = '8e2079508005379adb9a60798696134e'\n",
    "config.server = 'https://www.openml.org/api/v1'\n",
    "config.set_cache_directory(os.path.expanduser('~/openml-cache'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select and filter flows made by scikit learn\n",
    "flowsJson = flows.list_flows()\n",
    "flowList = pd.DataFrame.from_dict(flowsJson, orient='index')[['id','name']]\n",
    "pipelines = flowList.loc[flowList.name.str.startswith('sklearn.pipeline')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse pipelines and find valid pipelines \n",
    "pipelines = pipelines.assign(parsed = pipelines.name.map(lambda x: x[x.find('(') + 1:x.find(')') + 1]).map(lambda s : s.split(',')))\n",
    "pipelines = pipelines.assign(p_length = pipelines.parsed.map(lambda p: len(p)))\n",
    "pipelines = pipelines.query('p_length > 1')\n",
    "#pipelines.drop(['name'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove step names and extra punctuations\n",
    "pipelines.parsed = pipelines.parsed.map(lambda pi : map(lambda p: p[p.find('=') + 1 :], pi))\n",
    "pipelines.parsed = pipelines.parsed.map(lambda pi : map(lambda p: p.strip('()'), pi))\n",
    "flow_ids = pipelines.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendRun(df, nextBatch):\n",
    "    nb = pd.DataFrame.from_dict(nextBatch, orient='index')\n",
    "    return (pd.concat([df,nb]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_RUNS_LOC = '../../data/training-runs.csv'\n",
    "def readOrDownloadRuns():\n",
    "    if (os.path.exists(TRAINING_RUNS_LOC)):\n",
    "        trainingRuns = pd.read_csv(TRAINING_RUNS_LOC)\n",
    "        return (trainingRuns)\n",
    "    else:\n",
    "        size = 10000\n",
    "        offset = 0\n",
    "        rl = runs.list_runs(flow=flow_ids, size = size, offset = offset)\n",
    "        experiments = pd.DataFrame.from_dict(rl, orient='index')\n",
    "        try:\n",
    "            while(0 < 1):\n",
    "                offset = offset + size\n",
    "                rl = runs.list_runs(flow=flow_ids, size = size, offset = offset)\n",
    "                experiments = appendRun(experiments, rl)\n",
    "        except Exception:\n",
    "            print('finished reading')\n",
    "        trainingRuns = experiments.groupby(['setup_id', 'flow_id','task_id']).size().reset_index(name='counts')\n",
    "        trainingRuns.to_csv(TRAINING_RUNS_LOC, index=False)\n",
    "        return (trainingRuns)\n",
    "\n",
    "trainingRuns = readOrDownloadRuns()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setup_id</th>\n",
       "      <th>flow_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29246</td>\n",
       "      <td>5591</td>\n",
       "      <td>59</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29288</td>\n",
       "      <td>5653</td>\n",
       "      <td>145677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29293</td>\n",
       "      <td>5662</td>\n",
       "      <td>145677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29294</td>\n",
       "      <td>5663</td>\n",
       "      <td>145677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30231</td>\n",
       "      <td>5743</td>\n",
       "      <td>145677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   setup_id  flow_id  task_id  counts\n",
       "0     29246     5591       59      23\n",
       "1     29288     5653   145677       1\n",
       "2     29293     5662   145677       1\n",
       "3     29294     5663   145677       1\n",
       "4     30231     5743   145677       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingRuns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskIds = trainingRuns.task_id.unique()\n",
    "flowIds = trainingRuns.flow_id.unique()\n",
    "setupIds = trainingRuns.setup_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = pipelines.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation Table\n",
    "The Transformation table include the list of all the available transformations.\n",
    "The current version only support transformation available in scikit-learn\n",
    "Currently, the table has the following format:\n",
    "\n",
    "|id            | full_name     |\n",
    "|:------------ |:--------------|\n",
    "|id of the Transformation| Full name of the Transformation|\n",
    "\n",
    "TODO:\n",
    "- For each transformation, extract the required parameters as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all different transformations from the trainingRuns table\n",
    "# investiage training runs and the pipeline table do not have matching flow (pipeline) ids\n",
    "# even though the training run is queried from pipeline id column\n",
    "currentPipelines = pipelines[pipelines.id.isin(flowIds)].reset_index(drop=True)\n",
    "allTrasformations = []\n",
    "currentPipelines.parsed.map(lambda ts : [allTrasformations.append(a) for a in ts])\n",
    "transformations = pd.DataFrame(allTrasformations, columns=['full_name'])\n",
    "Transformation = pd.DataFrame({'id': transformations.full_name.unique(), 'full_name': transformations.full_name.unique()}, columns = ['id','full_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sklearn.preprocessing.imputation.Imputer</td>\n",
       "      <td>sklearn.preprocessing.imputation.Imputer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sklearn.preprocessing.data.OneHotEncoder</td>\n",
       "      <td>sklearn.preprocessing.data.OneHotEncoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sklearn.ensemble.forest.RandomForestClassifier</td>\n",
       "      <td>sklearn.ensemble.forest.RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>openml.utils.preprocessing.ConditionalImputer</td>\n",
       "      <td>openml.utils.preprocessing.ConditionalImputer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sklearn.feature_selection.variance_threshold.V...</td>\n",
       "      <td>sklearn.feature_selection.variance_threshold.V...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0           sklearn.preprocessing.imputation.Imputer   \n",
       "1           sklearn.preprocessing.data.OneHotEncoder   \n",
       "2     sklearn.ensemble.forest.RandomForestClassifier   \n",
       "3      openml.utils.preprocessing.ConditionalImputer   \n",
       "4  sklearn.feature_selection.variance_threshold.V...   \n",
       "\n",
       "                                           full_name  \n",
       "0           sklearn.preprocessing.imputation.Imputer  \n",
       "1           sklearn.preprocessing.data.OneHotEncoder  \n",
       "2     sklearn.ensemble.forest.RandomForestClassifier  \n",
       "3      openml.utils.preprocessing.ConditionalImputer  \n",
       "4  sklearn.feature_selection.variance_threshold.V...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Transformation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Table\n",
    "The Pipeline table contains information about the pipeline, consists of the model, the transformations, the dataset the pipeline is trained on, and parameters. \n",
    "The current version only support transformation available in scikit-learn Currently, the table has the following format:\n",
    "\n",
    "|id            | full_name     | model | transformations | hyperparameters | dataset |\n",
    "|:------------ |:--------------|:------|:----------------|:----------------|---------|\n",
    "|id | Full name| List of Transformations| learned model|hyper parameters of the transformations and the model| dataset|\n",
    "\n",
    "TODO:\n",
    "- Extract model\n",
    "- Extract hyperparameters\n",
    "- There are multiple setup ids for some combinatino of <flow,task>. Make sure that only the parameter values are different and not the actual parameter names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the pipeline info from the run and flow tables\n",
    "currentPipelines = pipelines[pipelines.id.isin(flowIds)].reset_index(drop=True)\n",
    "# Check the setup ids later. for now just ignore setup_id \n",
    "before = currentPipelines.merge(trainingRuns, left_on='id', right_on='flow_id')[['id','name','task_id','parsed']]\n",
    "dedulicated = before.drop_duplicates(subset=['id','task_id'])\n",
    "Pipeline = dedulicated.rename(columns = {\"name\":\"full_name\", \"parsed\":\"transformations\", \"task_id\":\"task\"})[['id','full_name','transformations','task']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_name</th>\n",
       "      <th>transformations</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5591</td>\n",
       "      <td>sklearn.pipeline.Pipeline(Imputer=sklearn.prep...</td>\n",
       "      <td>[sklearn.preprocessing.imputation.Imputer, skl...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5648</td>\n",
       "      <td>sklearn.pipeline.Pipeline(Imputer=openml.utils...</td>\n",
       "      <td>[openml.utils.preprocessing.ConditionalImputer...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5653</td>\n",
       "      <td>sklearn.pipeline.Pipeline(feature_select=sklea...</td>\n",
       "      <td>[sklearn.feature_selection.univariate_selectio...</td>\n",
       "      <td>145677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5662</td>\n",
       "      <td>sklearn.pipeline.Pipeline(scaling=sklearn.prep...</td>\n",
       "      <td>[sklearn.preprocessing.data.StandardScaler, sk...</td>\n",
       "      <td>145677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5663</td>\n",
       "      <td>sklearn.pipeline.Pipeline(scaling=sklearn.prep...</td>\n",
       "      <td>[sklearn.preprocessing.data.StandardScaler, sk...</td>\n",
       "      <td>145677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                          full_name  \\\n",
       "0  5591  sklearn.pipeline.Pipeline(Imputer=sklearn.prep...   \n",
       "2  5648  sklearn.pipeline.Pipeline(Imputer=openml.utils...   \n",
       "3  5653  sklearn.pipeline.Pipeline(feature_select=sklea...   \n",
       "4  5662  sklearn.pipeline.Pipeline(scaling=sklearn.prep...   \n",
       "5  5663  sklearn.pipeline.Pipeline(scaling=sklearn.prep...   \n",
       "\n",
       "                                     transformations    task  \n",
       "0  [sklearn.preprocessing.imputation.Imputer, skl...      59  \n",
       "2  [openml.utils.preprocessing.ConditionalImputer...      29  \n",
       "3  [sklearn.feature_selection.univariate_selectio...  145677  \n",
       "4  [sklearn.preprocessing.data.StandardScaler, sk...  145677  \n",
       "5  [sklearn.preprocessing.data.StandardScaler, sk...  145677  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pipeline.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Table\n",
    "The parameter table contains a list of all the parameters, (their type information), and their default values.\n",
    "The current version only support transformation available in scikit-learn Currently, the table has the following format:\n",
    "\n",
    "|id            | name     | full_name | default_value | type |\n",
    "|:------------ |:--------------|:------|:----------------|:----------------|\n",
    "|id |  name| Full Name| Default value|Type information|\n",
    "\n",
    "TODO:\n",
    "- Ensure that all that every setup for a specific flow has the exact same set of parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETER_LOC = '../../data/parameter.csv'\n",
    "def readOrDownloadParams():\n",
    "    if (os.path.exists(PARAMETER_LOC)):\n",
    "        parameter_table = pd.read_csv(TRAINING_RUNS_LOC)\n",
    "        return (parameter_table)\n",
    "    else:\n",
    "        all_setups = Pipeline.merge(trainingRuns, left_on='id', right_on='flow_id')[['id','setup_id']]\n",
    "        # have to check these to make sure that every setup for a flow contains exactly the same set of parameters\n",
    "        unique_parameters = all_setups.drop_duplicates(subset=['id'])\n",
    "        all_setups = setups.list_setups(setup=unique_parameters.setup_id)\n",
    "        parameter_table = pd.DataFrame(columns=['id','name','full_name','default_value','type'])\n",
    "        for sk, sv in all_setups.iteritems():\n",
    "            for pk, pv in sv.parameters.iteritems():\n",
    "                parameter_table.loc[Parameter.shape[0]] = [pv.id,pv.parameter_name,pv.full_name,pv.default_value,pv.data_type]\n",
    "        parameter_table.to_csv(PARAMETER_LOC, index=False)\n",
    "        return (parameter_table)\n",
    "Parameter = readOrDownloadParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>default_value</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53952</td>\n",
       "      <td>iterated_power</td>\n",
       "      <td>sklearn.decomposition.pca.PCA(1)_iterated_power</td>\n",
       "      <td>\"auto\"</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53953</td>\n",
       "      <td>n_components</td>\n",
       "      <td>sklearn.decomposition.pca.PCA(1)_n_components</td>\n",
       "      <td>null</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53954</td>\n",
       "      <td>random_state</td>\n",
       "      <td>sklearn.decomposition.pca.PCA(1)_random_state</td>\n",
       "      <td>null</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53955</td>\n",
       "      <td>svd_solver</td>\n",
       "      <td>sklearn.decomposition.pca.PCA(1)_svd_solver</td>\n",
       "      <td>\"auto\"</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53956</td>\n",
       "      <td>tol</td>\n",
       "      <td>sklearn.decomposition.pca.PCA(1)_tol</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            name                                        full_name  \\\n",
       "0  53952  iterated_power  sklearn.decomposition.pca.PCA(1)_iterated_power   \n",
       "1  53953    n_components    sklearn.decomposition.pca.PCA(1)_n_components   \n",
       "2  53954    random_state    sklearn.decomposition.pca.PCA(1)_random_state   \n",
       "3  53955      svd_solver      sklearn.decomposition.pca.PCA(1)_svd_solver   \n",
       "4  53956             tol             sklearn.decomposition.pca.PCA(1)_tol   \n",
       "\n",
       "  default_value  type  \n",
       "0        \"auto\"  None  \n",
       "1          null  None  \n",
       "2          null  None  \n",
       "3        \"auto\"  None  \n",
       "4           0.0  None  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parameter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Table\n",
    "The Dataset table contains metadata about the existing datasets in the training runs.\n",
    "First from the pipeline table, the tasks are extracted, then the correspoding dataset is retreived from OpenML.\n",
    "The table has the following schema:\n",
    "\n",
    "|id            | name     | NumberOfClasses | NumberOfFeatures | NumberOfInstances |\n",
    "|:------------ |:--------------|:------|:----------------|:----------------|\n",
    "|id |  name| Number of classes| Number of Features |Number of training instances|\n",
    "\n",
    "TODO:\n",
    "- OpenML contains more information about the Datasets, check if any other information are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_LOC = '../../data/dataset.csv'\n",
    "def readOrDownloadDatasets():\n",
    "    if (os.path.exists(DATASET_LOC)):\n",
    "        dataset_table = pd.read_csv(DATASET_LOC)\n",
    "        return (dataset_table)\n",
    "    else:\n",
    "        relatedTasks = Pipeline.task.unique()\n",
    "        taskList = []\n",
    "        for t in relatedTasks:\n",
    "            print 'retreiving task: ' + str(t)\n",
    "            try:\n",
    "                task = tasks.get_tasks(task_ids=[t])\n",
    "                taskList.append(task)\n",
    "            except Exception:\n",
    "                print 'error in task: ' + str (t)\n",
    "        datasetIds = []\n",
    "        mapping = dict()\n",
    "        for t in taskList:\n",
    "            mapping[t[0].task_id] = (t[0].datasetIds) \n",
    "\n",
    "        ds = datasets.list_datasets()\n",
    "        datasetTable = pd.DataFrame.from_dict(ds, orient='index')\n",
    "        existingDatasets = datasetTable[datasetTable.did.isin(mapping.values())]\n",
    "        dataset_table = existingDatasets.rename(columns = {\"did\":\"id\"})[['did','name', 'NumberOfClasses','NumberOfFeatures','NumberOfInstances']]\n",
    "        dataset_table.to_csv(DATASET_LOC, index=False)\n",
    "        return (dataset_table)\n",
    "Dataset = readOrDownloadDatasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>NumberOfClasses</th>\n",
       "      <th>NumberOfFeatures</th>\n",
       "      <th>NumberOfInstances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>anneal</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>labor</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>arrhythmia</td>\n",
       "      <td>13</td>\n",
       "      <td>280</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>letter</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>lymph</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        name  NumberOfClasses  NumberOfFeatures  NumberOfInstances\n",
       "0   2      anneal                5                39                898\n",
       "1   4       labor                2                17                 57\n",
       "2   5  arrhythmia               13               280                452\n",
       "3   6      letter               26                17              20000\n",
       "4  10       lymph                4                19                148"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping table to change the task id in Pipeline table to dataset\n",
    "Mapping = pd.DataFrame.from_dict(mapping,orient='index')\n",
    "Mapping['task'] = Mapping.index\n",
    "Mapping = Mapping.rename(columns = {0:'dataset'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  task\n",
       "1        1     1\n",
       "2        2     2\n",
       "4        4     4\n",
       "5        5     5\n",
       "6        6     6"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mapping.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing\n",
    "Modify the Pipeline and Training run tables to include the dataset id, instead of the task id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipeline = Pipeline.merge(Mapping, on='task', how='inner')[['id','full_name','transformations','dataset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_name</th>\n",
       "      <th>transformations</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5591</td>\n",
       "      <td>sklearn.pipeline.Pipeline(Imputer=sklearn.prep...</td>\n",
       "      <td>[sklearn.preprocessing.imputation.Imputer, skl...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5804</td>\n",
       "      <td>sklearn.pipeline.Pipeline(pca=sklearn.decompos...</td>\n",
       "      <td>[sklearn.decomposition.pca.PCA, sklearn.ensemb...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5873</td>\n",
       "      <td>sklearn.pipeline.Pipeline(Imputer=openml.utils...</td>\n",
       "      <td>[openml.utils.preprocessing.ConditionalImputer...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5983</td>\n",
       "      <td>sklearn.pipeline.Pipeline(dualimputer=helper.d...</td>\n",
       "      <td>[helper.dual_imputer.DualImputer, sklearn.prep...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6038</td>\n",
       "      <td>sklearn.pipeline.Pipeline(dualimputer=helper.d...</td>\n",
       "      <td>[helper.dual_imputer.DualImputer, sklearn.neig...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                          full_name  \\\n",
       "0  5591  sklearn.pipeline.Pipeline(Imputer=sklearn.prep...   \n",
       "1  5804  sklearn.pipeline.Pipeline(pca=sklearn.decompos...   \n",
       "2  5873  sklearn.pipeline.Pipeline(Imputer=openml.utils...   \n",
       "3  5983  sklearn.pipeline.Pipeline(dualimputer=helper.d...   \n",
       "4  6038  sklearn.pipeline.Pipeline(dualimputer=helper.d...   \n",
       "\n",
       "                                     transformations  dataset  \n",
       "0  [sklearn.preprocessing.imputation.Imputer, skl...       61  \n",
       "1  [sklearn.decomposition.pca.PCA, sklearn.ensemb...       61  \n",
       "2  [openml.utils.preprocessing.ConditionalImputer...       61  \n",
       "3  [helper.dual_imputer.DualImputer, sklearn.prep...       61  \n",
       "4  [helper.dual_imputer.DualImputer, sklearn.neig...       61  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pipeline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
